{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGPR5VXwI+JyUVyjIifMhd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imbrunire/DigiMAB/blob/main/automatic_metadata_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Librerie necessarie e programmi\n",
        "Programma: exiftool\n",
        "\n",
        "Librerie:"
      ],
      "metadata": {
        "id": "SYcEmz4O6t-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic pillow"
      ],
      "metadata": {
        "id": "2LM1dFd40QHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estrazione programmatica dei metadati\n",
        "\n",
        "Input: immagini delle carte facenti parte di un oggetto digitale, file Word con la scheda descrittiva.\n",
        "\n",
        "1.   **Estrazione dei metadati tecnici**\n",
        "\n",
        "Scaricare in locale il programma [exiftool](https://https://exiftool.org/) e aggiungerlo al path che si trova nelle variabili d'ambiente del proprio computer. Dai metadati tecnici che sono parte integrante dell'immagine analizzata, questo codice estrae il formato dell'immagine (jpeg, png..), l'altezza e la larghezza, l'estensione dell'immagine, e lo strumento utilizzato per l'acquisizione. Viene utilizzata la libreria python hashlib per calcolare l'impronta digitale del documento MD5.\n",
        "\n",
        "\n",
        "2.   **Estrazione dei metadati descrittivi inseriti manualmente**\n",
        "\n",
        "Alcuni field di metadati dovranno essere inseriti manualmente per garantire accuratezza e correttezza. Si tratta di metadati che difficilmente AI potrebbe riconoscere in modo puntuale, come la filigrana del documento, l'istituto collettore, la materia, la creazione, l'autore, le dimensioni in mm del documento, lo stato di conservazione, la storia del manoscritto. In questo codice si √® presupposto che i metadati vengano inseriti manualmente all'interno di una scheda descrittiva redatta utilizzando microsoft Word. Il codice, quindi, si occupa di estrarre la gerarchia di elementi presenti nel file Word e di formattarli come metadati.\n",
        "\n",
        "A che cosa servono questi metadati estratti programmaticamente o inseriti  manualmente?\n",
        "Sono sia una base di partenza per la costruzione di metadati corretti, sia possono essere utilizzati come contesto utile per migliorare l'efficacia dell'estrazione automatizzata di metadati tramite AI.\n",
        "\n",
        "Output: due file JSON:\n",
        "1) uno contenente i metadati completi, ovvero ci√≤ che viene estratto dal file Word assieme ai metadati tecnici estratti con exiftool;\n",
        "2) uno contenente dei metadati essenziali, ovvero dei metadati scelti, da passare come contesto al LLM.\n",
        "\n",
        "I metadati essenziali sono strutturati nel seguente modo:\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "  \"CNMD0000424280\": {\n",
        "    \"metadati_descrittivi\": {\n",
        "      \"segnatura\": \"CNMD\\\\0000424280\",\n",
        "      \"data_creazione\": \"1814-01-24\",\n",
        "      \"materia\": \"Cartaceo\",\n",
        "      \"numero_carte\": \"c. 1\",\n",
        "      \"stato_conservazione\": \"Buono\",\n",
        "      \"luogo_creazione\": \"Roma\",\n",
        "      \"autore\": \"Francesco Cancellieri\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "A questi metadati essenziali potrebbero essere aggiunti altri come il tipo di scrittura (carolina, cancelleresca...) e la tipologia di documento (copia, autografo...).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z1TSD7920StS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "import subprocess\n",
        "import json\n",
        "import hashlib\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def processa_contenuto(paragraph_text):\n",
        "    righe = [r.strip() for r in paragraph_text.split(\"\\n\") if r.strip()]\n",
        "    risultati = []\n",
        "    for r in righe:\n",
        "        if \":\" in r:\n",
        "            k, v = r.split(\":\", 1)\n",
        "            risultati.append({k.strip(): v.strip()})\n",
        "        else:\n",
        "            risultati.append({\"testo\": r})\n",
        "    return risultati\n",
        "\n",
        "def clean_node(node):\n",
        "    \"\"\"Rimuove campi vuoti e applica ricorsivamente ai figli\"\"\"\n",
        "    cleaned = {\"titolo\": node[\"titolo\"]}\n",
        "\n",
        "    if node.get(\"contenuto\"):\n",
        "        cleaned[\"contenuto\"] = node[\"contenuto\"]\n",
        "\n",
        "    if node.get(\"figli\"):\n",
        "        cleaned[\"figli\"] = [clean_node(f) for f in node[\"figli\"]]\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "def estrai_gerarchia(path):\n",
        "    doc = Document(path)\n",
        "    struttura = []\n",
        "    stack = []\n",
        "\n",
        "    for p in doc.paragraphs:\n",
        "        testo = p.text.strip()\n",
        "        if not testo:\n",
        "            continue\n",
        "\n",
        "        style = p.style.name\n",
        "\n",
        "        if style.startswith(\"Heading\"):\n",
        "            livello = int(style.replace(\"Heading \", \"\"))\n",
        "            nodo = {\"titolo\": testo, \"livello\": livello, \"contenuto\": [], \"figli\": []}\n",
        "\n",
        "            while stack and stack[-1][\"livello\"] >= livello:\n",
        "                stack.pop()\n",
        "\n",
        "            if not stack:\n",
        "                struttura.append(nodo)\n",
        "            else:\n",
        "                stack[-1][\"figli\"].append(nodo)\n",
        "\n",
        "            stack.append(nodo)\n",
        "\n",
        "        else:\n",
        "            if stack:\n",
        "                stack[-1][\"contenuto\"].extend(processa_contenuto(testo))\n",
        "            else:\n",
        "                struttura.append({\n",
        "                    \"titolo\": None,\n",
        "                    \"livello\": 0,\n",
        "                    \"contenuto\": processa_contenuto(testo),\n",
        "                    \"figli\": []\n",
        "                })\n",
        "\n",
        "    return [clean_node(n) for n in struttura]\n",
        "\n",
        "def calcola_md5(file_path):\n",
        "    \"\"\"Calcola l'impronta MD5 di un file\"\"\"\n",
        "    hash_md5 = hashlib.md5()\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "            hash_md5.update(chunk)\n",
        "    return hash_md5.hexdigest()\n",
        "\n",
        "def estrai_metadati_immagine(file_immagine):\n",
        "    \"\"\"Estrae metadati tecnici da un'immagine\"\"\"\n",
        "    impronta = calcola_md5(file_immagine)\n",
        "\n",
        "    campi = [\"FileType\", \"ImageWidth\", \"ImageHeight\", \"FileTypeExtension\", \"Model\"]\n",
        "    result = subprocess.run(\n",
        "        [\"exiftool\", *[\"-\" + c for c in campi], \"-json\", file_immagine],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    metadati = json.loads(result.stdout)[0]\n",
        "\n",
        "    return {\n",
        "        \"nome_file\": os.path.basename(file_immagine),\n",
        "        \"impronta_md5\": impronta,\n",
        "        \"metadati_tecnici\": {\n",
        "            \"formato_file\": metadati.get(\"FileType\"),\n",
        "            \"risoluzione\": {\n",
        "                \"larghezza\": metadati.get(\"ImageWidth\"),\n",
        "                \"altezza\": metadati.get(\"ImageHeight\")\n",
        "            },\n",
        "            \"estensione_file\": metadati.get(\"FileTypeExtension\"),\n",
        "            \"strumento_acquisizione\": metadati.get(\"Model\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "def trova_valore_in_contenuto(contenuto, chiave):\n",
        "    \"\"\"Cerca un valore in una lista di dizionari contenuto\"\"\"\n",
        "    if not contenuto:\n",
        "        return None\n",
        "    for item in contenuto:\n",
        "        if chiave in item:\n",
        "            return item[chiave]\n",
        "    return None\n",
        "\n",
        "def estrai_metadati_essenziali(struttura_completa):\n",
        "    \"\"\"Estrae solo i metadati descrittivi essenziali dalla struttura gerarchica\"\"\"\n",
        "\n",
        "    metadati_essenziali = {}\n",
        "\n",
        "    # Naviga la struttura per trovare le sezioni rilevanti\n",
        "    for sezione in struttura_completa:\n",
        "        titolo_principale = sezione.get(\"titolo\", \"\")\n",
        "\n",
        "        # Istituto e segnatura (dal titolo principale)\n",
        "        if titolo_principale and \"CNMD\" in titolo_principale:\n",
        "            metadati_essenziali[\"segnatura\"] = titolo_principale\n",
        "\n",
        "        # Cerca nelle sottosezioni\n",
        "        for figlio in sezione.get(\"figli\", []):\n",
        "            titolo_sezione = figlio.get(\"titolo\", \"\")\n",
        "            contenuto = figlio.get(\"contenuto\", [])\n",
        "\n",
        "            # IDENTIFICAZIONE\n",
        "            if titolo_sezione == \"IDENTIFICAZIONE DEL MANOSCRITTO\":\n",
        "                cnmd = trova_valore_in_contenuto(contenuto, \"CNMD\")\n",
        "                if cnmd:\n",
        "                    metadati_essenziali[\"segnatura\"] = cnmd\n",
        "\n",
        "            # DATAZIONE\n",
        "            elif titolo_sezione == \"DATAZIONE\":\n",
        "                data = trova_valore_in_contenuto(contenuto, \"Data\")\n",
        "                if data:\n",
        "                    metadati_essenziali[\"data_creazione\"] = data\n",
        "\n",
        "            # MATERIA\n",
        "            elif titolo_sezione == \"MATERIA\":\n",
        "                for sottosezione in figlio.get(\"figli\", []):\n",
        "                    if sottosezione.get(\"titolo\") == \"CORPO DEL CODICE\":\n",
        "                        materia = trova_valore_in_contenuto(sottosezione.get(\"contenuto\", []), \"Materia\")\n",
        "                        if materia:\n",
        "                            metadati_essenziali[\"materia\"] = materia\n",
        "\n",
        "            # DIMENSIONI\n",
        "            elif titolo_sezione == \"DIMENSIONI\":\n",
        "                carte = trova_valore_in_contenuto(contenuto, \"Carte\")\n",
        "\n",
        "                if carte:\n",
        "                    metadati_essenziali[\"numero_carte\"] = carte\n",
        "\n",
        "            # STATO DI CONSERVAZIONE\n",
        "            elif titolo_sezione == \"STATO DI CONSERVAZIONE E RESTAURO\":\n",
        "                for sottosezione in figlio.get(\"figli\", []):\n",
        "                    if sottosezione.get(\"titolo\") == \"STATO DI CONSERVAZIONE\":\n",
        "                        stato = trova_valore_in_contenuto(sottosezione.get(\"contenuto\", []), \"Stato di conservazione\")\n",
        "                        if stato:\n",
        "                            metadati_essenziali[\"stato_conservazione\"] = stato\n",
        "\n",
        "\n",
        "        # Cerca informazioni sul carteggio (per autore e titolo)\n",
        "        if \"Carteggio\" in titolo_principale or \"lettera\" in str(sezione).lower():\n",
        "            for figlio in sezione.get(\"figli\", []):\n",
        "                # NOMI LEGATI AL CARTEGGIO\n",
        "                if figlio.get(\"titolo\") == \"NOMI LEGATI AL CARTEGGIO\":\n",
        "                    contenuto = figlio.get(\"contenuto\", [])\n",
        "                    # Cerca mittente e destinatario\n",
        "                    nome_idx = 0\n",
        "                    while nome_idx < len(contenuto):\n",
        "                        if \"Nome (forma accettata o identificata)\" in contenuto[nome_idx]:\n",
        "                            nome = contenuto[nome_idx][\"Nome (forma accettata o identificata)\"]\n",
        "                            # Controlla la responsabilit√† nel prossimo elemento\n",
        "                            if nome_idx + 1 < len(contenuto) and \"Responsabilit√†\" in contenuto[nome_idx + 1]:\n",
        "                                responsabilita = contenuto[nome_idx + 1][\"Responsabilit√†\"]\n",
        "                                if responsabilita == \"mittente\":\n",
        "                                    metadati_essenziali[\"autore\"] = nome\n",
        "                        nome_idx += 1\n",
        "\n",
        "                # DESCRIZIONE GENERALE per tipologia e luogo\n",
        "                if figlio.get(\"titolo\") == \"DESCRIZIONE GENERALE\":\n",
        "                    contenuto = figlio.get(\"contenuto\", [])\n",
        "\n",
        "                    # Cerca luogo nelle sottosezioni\n",
        "                    for sottosezione in figlio.get(\"figli\", []):\n",
        "                        if sottosezione.get(\"titolo\") == \"LUOGO\":\n",
        "                            luogo_spedizione = trova_valore_in_contenuto(sottosezione.get(\"contenuto\", []), \"Luogo di spedizione\")\n",
        "                            if luogo_spedizione:\n",
        "                                metadati_essenziali[\"luogo_creazione\"] = luogo_spedizione\n",
        "\n",
        "    return metadati_essenziali\n",
        "\n",
        "def estrai_metadati_completi(docx_path, cartella_immagini, output_completo=\"metadati_completi.json\", output_essenziale=\"metadati_essenziali.json\"):\n",
        "    \"\"\"\n",
        "    Estrae metadati dal file Word e da tutte le immagini nella cartella\n",
        "    Crea due file JSON: uno completo e uno con solo i metadati essenziali\n",
        "    \"\"\"\n",
        "    # Estrai metadati dal documento Word\n",
        "    metadati_documento = estrai_gerarchia(docx_path)\n",
        "\n",
        "    # Trova tutte le immagini nella cartella\n",
        "    estensioni_immagini = {'.jpg', '.jpeg', '.png', '.tif', '.tiff', '.bmp'}\n",
        "    immagini = []\n",
        "\n",
        "    if os.path.isdir(cartella_immagini):\n",
        "        for file in sorted(os.listdir(cartella_immagini)):\n",
        "            if Path(file).suffix.lower() in estensioni_immagini:\n",
        "                file_path = os.path.join(cartella_immagini, file)\n",
        "                try:\n",
        "                    metadati_img = estrai_metadati_immagine(file_path)\n",
        "                    immagini.append(metadati_img)\n",
        "                    print(f\"‚úì Elaborata: {file}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚úó Errore con {file}: {e}\")\n",
        "\n",
        "    nome_oggetto = docx_path.split('.')[0]\n",
        "    print(nome_oggetto)\n",
        "\n",
        "    # Crea struttura completa\n",
        "    output_comp = {\n",
        "        nome_oggetto: {\n",
        "            \"metadati_descrittivi\": metadati_documento,\n",
        "            \"immagini\": immagini,\n",
        "            \"statistiche\": {\n",
        "                \"numero_immagini\": len(immagini)\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Salva JSON completo\n",
        "    with open(output_completo, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(output_comp, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # Estrai metadati essenziali\n",
        "    metadati_essenziali = estrai_metadati_essenziali(metadati_documento)\n",
        "\n",
        "    # Crea struttura essenziale\n",
        "    output_ess = {\n",
        "        nome_oggetto: {\n",
        "            \"metadati_descrittivi\": metadati_essenziali\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Salva JSON essenziale\n",
        "    with open(output_essenziale, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(output_ess, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\n‚úì JSON completo creato: {output_completo}\")\n",
        "    print(f\"‚úì JSON essenziale creato: {output_essenziale}\")\n",
        "    print(f\"  - Metadati descrittivi estratti da: {docx_path}\")\n",
        "    print(f\"  - Immagini elaborate: {len(immagini)}\")\n",
        "    print(f\"  - Campi essenziali estratti: {len(metadati_essenziali)}\")\n",
        "\n",
        "    return output_comp, output_ess\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    docx_path = \"CNMD0000424561.docx\"\n",
        "\n",
        "    estrai_metadati_completi(\n",
        "        docx_path=docx_path,\n",
        "        cartella_immagini=\"./05.1289\",\n",
        "        output_completo=f\"{docx_path.split('.')[0]}_metadati_completi.json\",\n",
        "        output_essenziale=f\"{docx_path.split('.')[0]}_metadati_essenziali.json\"\n",
        "    )"
      ],
      "metadata": {
        "id": "yPXZKHaQz1el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estrazione dei metadati tecnici e descrittivi inseriti manualmente nel caso in cui l'oggetto digitale sia costituito da pi√π unit√† codicologiche"
      ],
      "metadata": {
        "id": "6C83pLng0luB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "import subprocess\n",
        "import json\n",
        "import hashlib\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "def processa_contenuto(paragraph_text):\n",
        "    righe = [r.strip() for r in paragraph_text.split(\"\\n\") if r.strip()]\n",
        "    risultati = []\n",
        "    for r in righe:\n",
        "        if \":\" in r:\n",
        "            k, v = r.split(\":\", 1)\n",
        "            risultati.append({k.strip(): v.strip()})\n",
        "        else:\n",
        "            risultati.append({\"testo\": r})\n",
        "    return risultati\n",
        "\n",
        "def clean_node(node):\n",
        "    \"\"\"Rimuove campi vuoti e applica ricorsivamente ai figli\"\"\"\n",
        "    cleaned = {\"titolo\": node[\"titolo\"]}\n",
        "\n",
        "    if node.get(\"contenuto\"):\n",
        "        cleaned[\"contenuto\"] = node[\"contenuto\"]\n",
        "\n",
        "    if node.get(\"figli\"):\n",
        "        cleaned[\"figli\"] = [clean_node(f) for f in node[\"figli\"]]\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "def estrai_gerarchia(path):\n",
        "    doc = Document(path)\n",
        "    struttura = []\n",
        "    stack = []\n",
        "\n",
        "    for p in doc.paragraphs:\n",
        "        testo = p.text.strip()\n",
        "        if not testo:\n",
        "            continue\n",
        "\n",
        "        style = p.style.name\n",
        "\n",
        "        if style.startswith(\"Heading\"):\n",
        "            livello = int(style.replace(\"Heading \", \"\"))\n",
        "            nodo = {\"titolo\": testo, \"livello\": livello, \"contenuto\": [], \"figli\": []}\n",
        "\n",
        "            while stack and stack[-1][\"livello\"] >= livello:\n",
        "                stack.pop()\n",
        "\n",
        "            if not stack:\n",
        "                struttura.append(nodo)\n",
        "            else:\n",
        "                stack[-1][\"figli\"].append(nodo)\n",
        "\n",
        "            stack.append(nodo)\n",
        "\n",
        "        else:\n",
        "            if stack:\n",
        "                stack[-1][\"contenuto\"].extend(processa_contenuto(testo))\n",
        "            else:\n",
        "                struttura.append({\n",
        "                    \"titolo\": None,\n",
        "                    \"livello\": 0,\n",
        "                    \"contenuto\": processa_contenuto(testo),\n",
        "                    \"figli\": []\n",
        "                })\n",
        "\n",
        "    return [clean_node(n) for n in struttura]\n",
        "\n",
        "def calcola_md5(file_path):\n",
        "    \"\"\"Calcola l'impronta MD5 di un file\"\"\"\n",
        "    hash_md5 = hashlib.md5()\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "            hash_md5.update(chunk)\n",
        "    return hash_md5.hexdigest()\n",
        "\n",
        "def estrai_metadati_immagine(file_immagine):\n",
        "    \"\"\"Estrae metadati tecnici da un'immagine\"\"\"\n",
        "    impronta = calcola_md5(file_immagine)\n",
        "\n",
        "    campi = [\"FileType\", \"ImageWidth\", \"ImageHeight\", \"FileTypeExtension\", \"Model\"]\n",
        "    result = subprocess.run(\n",
        "        [\"exiftool\", *[\"-\" + c for c in campi], \"-json\", file_immagine],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    metadati = json.loads(result.stdout)[0]\n",
        "\n",
        "    return {\n",
        "        \"nome_file\": os.path.basename(file_immagine),\n",
        "        \"impronta_md5\": impronta,\n",
        "        \"metadati_tecnici\": {\n",
        "            \"formato_file\": metadati.get(\"FileType\"),\n",
        "            \"risoluzione\": {\n",
        "                \"larghezza\": metadati.get(\"ImageWidth\"),\n",
        "                \"altezza\": metadati.get(\"ImageHeight\")\n",
        "            },\n",
        "            \"estensione_file\": metadati.get(\"FileTypeExtension\"),\n",
        "            \"strumento_acquisizione\": metadati.get(\"Model\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "def trova_valore_in_contenuto(contenuto, chiave):\n",
        "    \"\"\"Cerca un valore in una lista di dizionari contenuto\"\"\"\n",
        "    if not contenuto:\n",
        "        return None\n",
        "    for item in contenuto:\n",
        "        if chiave in item:\n",
        "            return item[chiave]\n",
        "    return None\n",
        "\n",
        "def identifica_unita_codicologiche(struttura_completa):\n",
        "    \"\"\"\n",
        "    Identifica e separa le diverse unit√† codicologiche nel documento\n",
        "    Restituisce: (descrizione_esterna, lista_unita_interne)\n",
        "    \"\"\"\n",
        "    descrizione_esterna = None\n",
        "    unita_interne = []\n",
        "\n",
        "    for sezione in struttura_completa:\n",
        "        titolo = sezione.get(\"titolo\", \"\")\n",
        "\n",
        "        if \"Descrizione esterna\" in titolo:\n",
        "            descrizione_esterna = sezione\n",
        "        elif \"Descrizione interna\" in titolo or \"Carteggio\" in titolo:\n",
        "            # Estrai numero unit√† dal titolo (es: \"Descrizione interna: 1, cc. 1r-2v\")\n",
        "            match = re.search(r':\\s*(\\d+)', titolo)\n",
        "            numero_unita = int(match.group(1)) if match else len(unita_interne) + 1\n",
        "\n",
        "            unita_interne.append({\n",
        "                \"numero\": numero_unita,\n",
        "                \"tipo\": \"Descrizione interna\" if \"Descrizione interna\" in titolo else \"Carteggio\",\n",
        "                \"sezione\": sezione\n",
        "            })\n",
        "\n",
        "    # Ordina per numero\n",
        "    unita_interne.sort(key=lambda x: x[\"numero\"])\n",
        "\n",
        "    return descrizione_esterna, unita_interne\n",
        "\n",
        "def estrai_metadati_descrizione_esterna(descrizione_esterna):\n",
        "    \"\"\"Estrae metadati dalla descrizione esterna (comuni a tutte le unit√†)\"\"\"\n",
        "    if not descrizione_esterna:\n",
        "        return {}\n",
        "\n",
        "    metadati = {}\n",
        "\n",
        "    for figlio in descrizione_esterna.get(\"figli\", []):\n",
        "        titolo_sezione = figlio.get(\"titolo\", \"\")\n",
        "        contenuto = figlio.get(\"contenuto\", [])\n",
        "\n",
        "        # IDENTIFICAZIONE\n",
        "        if \"IDENTIFICAZIONE\" in titolo_sezione:\n",
        "            cnmd = trova_valore_in_contenuto(contenuto, \"CNMD\")\n",
        "            if cnmd:\n",
        "                metadati[\"segnatura\"] = cnmd\n",
        "\n",
        "        # DATAZIONE\n",
        "        elif \"DATAZIONE\" in titolo_sezione:\n",
        "            data = trova_valore_in_contenuto(contenuto, \"Data\")\n",
        "            if data:\n",
        "                metadati[\"data_creazione\"] = data\n",
        "\n",
        "        # MATERIA\n",
        "        elif \"MATERIA\" in titolo_sezione:\n",
        "            for sottosezione in figlio.get(\"figli\", []):\n",
        "                if \"CORPO DEL CODICE\" in sottosezione.get(\"titolo\", \"\"):\n",
        "                    materia = trova_valore_in_contenuto(sottosezione.get(\"contenuto\", []), \"Materia\")\n",
        "                    if materia:\n",
        "                        metadati[\"materia\"] = materia\n",
        "\n",
        "        # STATO DI CONSERVAZIONE\n",
        "        elif \"STATO DI CONSERVAZIONE\" in titolo_sezione:\n",
        "            for sottosezione in figlio.get(\"figli\", []):\n",
        "                if \"STATO DI CONSERVAZIONE\" in sottosezione.get(\"titolo\", \"\"):\n",
        "                    stato = trova_valore_in_contenuto(sottosezione.get(\"contenuto\", []), \"Stato di conservazione\")\n",
        "                    if stato:\n",
        "                        metadati[\"stato_conservazione\"] = stato\n",
        "\n",
        "        # STORIA DEL MANOSCRITTO\n",
        "        elif \"STORIA DEL MANOSCRITTO\" in titolo_sezione:\n",
        "            data_entrata = trova_valore_in_contenuto(contenuto, \"Data di entrata del ms. in biblioteca\")\n",
        "            if data_entrata:\n",
        "                metadati[\"data_entrata_biblioteca\"] = data_entrata\n",
        "\n",
        "    return metadati\n",
        "\n",
        "def estrai_metadati_unita_interna(unita):\n",
        "    \"\"\"Estrae metadati specifici di una singola unit√† codicologica\"\"\"\n",
        "    sezione = unita[\"sezione\"]\n",
        "    metadati = {\n",
        "        \"numero_unita\": unita[\"numero\"],\n",
        "        \"tipo_unita\": unita[\"tipo\"]\n",
        "    }\n",
        "\n",
        "    for figlio in sezione.get(\"figli\", []):\n",
        "        titolo_sezione = figlio.get(\"titolo\", \"\")\n",
        "        contenuto = figlio.get(\"contenuto\", [])\n",
        "\n",
        "        # DESCRIZIONE GENERALE\n",
        "        if \"DESCRIZIONE GENERALE\" in titolo_sezione:\n",
        "            posizione = trova_valore_in_contenuto(contenuto, \"Posizione\")\n",
        "            if posizione:\n",
        "                metadati[\"posizione\"] = posizione\n",
        "\n",
        "            tipologia = trova_valore_in_contenuto(contenuto, \"Tipologia\")\n",
        "            if tipologia:\n",
        "                metadati[\"tipologia\"] = tipologia\n",
        "\n",
        "            autografo = trova_valore_in_contenuto(contenuto, \"Testo autografo\")\n",
        "            if autografo:\n",
        "                metadati[\"autografo\"] = autografo\n",
        "\n",
        "            note = trova_valore_in_contenuto(contenuto, \"Note\")\n",
        "            if note:\n",
        "                metadati[\"note\"] = note\n",
        "\n",
        "            # Cerca anche nelle sottosezioni (LUOGO, DATAZIONE)\n",
        "            for sottosezione in figlio.get(\"figli\", []):\n",
        "                sotto_titolo = sottosezione.get(\"titolo\", \"\")\n",
        "                sotto_contenuto = sottosezione.get(\"contenuto\", [])\n",
        "\n",
        "                if \"LUOGO\" in sotto_titolo:\n",
        "                    luogo_spedizione = trova_valore_in_contenuto(sotto_contenuto, \"Luogo di spedizione\")\n",
        "                    if luogo_spedizione:\n",
        "                        metadati[\"luogo_spedizione\"] = luogo_spedizione\n",
        "\n",
        "                if \"DATAZIONE\" in sotto_titolo:\n",
        "                    data = trova_valore_in_contenuto(sotto_contenuto, \"Data\")\n",
        "                    if data:\n",
        "                        metadati[\"data_specifica\"] = data\n",
        "\n",
        "        # NOMI LEGATI\n",
        "        elif \"NOMI LEGATI\" in titolo_sezione:\n",
        "            nomi = []\n",
        "            nome_idx = 0\n",
        "            while nome_idx < len(contenuto):\n",
        "                if \"Nome (forma accettata o identificata)\" in contenuto[nome_idx]:\n",
        "                    nome = contenuto[nome_idx][\"Nome (forma accettata o identificata)\"]\n",
        "                    if nome_idx + 1 < len(contenuto) and \"Responsabilit√†\" in contenuto[nome_idx + 1]:\n",
        "                        responsabilita = contenuto[nome_idx + 1][\"Responsabilit√†\"]\n",
        "                        nomi.append({\n",
        "                            \"nome\": nome,\n",
        "                            \"responsabilita\": responsabilita\n",
        "                        })\n",
        "                        if responsabilita == \"autore\" or responsabilita == \"mittente\":\n",
        "                            metadati[\"autore\"] = nome\n",
        "                nome_idx += 1\n",
        "            if nomi:\n",
        "                metadati[\"nomi_associati\"] = nomi\n",
        "\n",
        "        # TITOLI\n",
        "        elif \"TITOLI\" in titolo_sezione:\n",
        "            titolo = trova_valore_in_contenuto(contenuto, \"Titolo\")\n",
        "            if titolo:\n",
        "                metadati[\"titolo\"] = titolo\n",
        "\n",
        "            titolo_elaborato = trova_valore_in_contenuto(contenuto, \"Titolo elaborato\")\n",
        "            if titolo_elaborato:\n",
        "                metadati[\"titolo\"] = titolo_elaborato\n",
        "\n",
        "    return metadati\n",
        "\n",
        "def estrai_numero_unita_da_filename(filename):\n",
        "    \"\"\"\n",
        "    Estrae il numero dell'unit√† codicologica dal nome del file\n",
        "    Es: MC0069_CNMD0000424660.3_00001.jpg -> 3\n",
        "    \"\"\"\n",
        "    match = re.search(r'CNMD\\d+\\.(\\d+)', filename)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "def associa_immagini_a_unita(immagini, num_unita):\n",
        "    \"\"\"\n",
        "    Raggruppa le immagini per unit√† codicologica\n",
        "    \"\"\"\n",
        "    immagini_per_unita = {i: [] for i in range(1, num_unita + 1)}\n",
        "    immagini_generali = []\n",
        "\n",
        "    for img in immagini:\n",
        "        num_unita_img = estrai_numero_unita_da_filename(img[\"nome_file\"])\n",
        "        if num_unita_img and num_unita_img in immagini_per_unita:\n",
        "            immagini_per_unita[num_unita_img].append(img)\n",
        "        else:\n",
        "            immagini_generali.append(img)\n",
        "\n",
        "    return immagini_per_unita, immagini_generali\n",
        "\n",
        "def estrai_metadati_completi(docx_path, cartella_immagini,\n",
        "                            output_completo=\"metadati_completi.json\",\n",
        "                            output_essenziale=\"metadati_essenziali.json\"):\n",
        "    \"\"\"\n",
        "    Estrae metadati dal file Word riconoscendo le diverse unit√† codicologiche\n",
        "    \"\"\"\n",
        "    # Estrai struttura gerarchica dal documento\n",
        "    struttura_completa = estrai_gerarchia(docx_path)\n",
        "\n",
        "    # Identifica unit√† codicologiche\n",
        "    desc_esterna, unita_interne = identifica_unita_codicologiche(struttura_completa)\n",
        "\n",
        "    # Estrai metadati comuni (descrizione esterna)\n",
        "    metadati_comuni = estrai_metadati_descrizione_esterna(desc_esterna)\n",
        "\n",
        "    # Estrai metadati per ogni unit√† interna\n",
        "    unita_metadati = []\n",
        "    for unita in unita_interne:\n",
        "        metadati_unita = estrai_metadati_unita_interna(unita)\n",
        "        unita_metadati.append(metadati_unita)\n",
        "\n",
        "    # Elabora immagini\n",
        "    estensioni_immagini = {'.jpg', '.jpeg', '.png', '.tif', '.tiff', '.bmp'}\n",
        "    tutte_immagini = []\n",
        "\n",
        "    if os.path.isdir(cartella_immagini):\n",
        "        for file in sorted(os.listdir(cartella_immagini)):\n",
        "            if Path(file).suffix.lower() in estensioni_immagini:\n",
        "                file_path = os.path.join(cartella_immagini, file)\n",
        "                try:\n",
        "                    metadati_img = estrai_metadati_immagine(file_path)\n",
        "                    tutte_immagini.append(metadati_img)\n",
        "                    print(f\"‚úì Elaborata: {file}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚úó Errore con {file}: {e}\")\n",
        "\n",
        "    # Associa immagini alle unit√†\n",
        "    immagini_per_unita, immagini_generali = associa_immagini_a_unita(\n",
        "        tutte_immagini,\n",
        "        len(unita_interne)\n",
        "    )\n",
        "\n",
        "    # Nome oggetto dal file DOCX\n",
        "    nome_oggetto = Path(docx_path).stem\n",
        "\n",
        "    # Struttura completa\n",
        "    output_comp = {\n",
        "        nome_oggetto: {\n",
        "            \"metadati_descrittivi_comuni\": metadati_comuni,\n",
        "            \"unita_codicologiche\": [],\n",
        "            \"immagini_generali\": immagini_generali,\n",
        "            \"struttura_completa\": struttura_completa,\n",
        "            \"statistiche\": {\n",
        "                \"numero_unita\": len(unita_interne),\n",
        "                \"numero_immagini_totali\": len(tutte_immagini)\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Aggiungi ogni unit√† con le sue immagini\n",
        "    for i, metadati_unita in enumerate(unita_metadati, 1):\n",
        "        output_comp[nome_oggetto][\"unita_codicologiche\"].append({\n",
        "            \"metadati\": metadati_unita,\n",
        "            \"immagini\": immagini_per_unita[i]\n",
        "        })\n",
        "\n",
        "    # Salva JSON completo\n",
        "    with open(output_completo, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(output_comp, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # Crea versione essenziale\n",
        "    output_ess = {\n",
        "        nome_oggetto: {\n",
        "            \"metadati_comuni\": metadati_comuni,\n",
        "            \"unita\": [m for m in unita_metadati]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Salva JSON essenziale\n",
        "    with open(output_essenziale, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(output_ess, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\n‚úì JSON completo creato: {output_completo}\")\n",
        "    print(f\"‚úì JSON essenziale creato: {output_essenziale}\")\n",
        "    print(f\"  - Unit√† codicologiche identificate: {len(unita_interne)}\")\n",
        "    print(f\"  - Immagini totali elaborate: {len(tutte_immagini)}\")\n",
        "    for i in range(1, len(unita_interne) + 1):\n",
        "        print(f\"    ‚Ä¢ Unit√† {i}: {len(immagini_per_unita[i])} immagini\")\n",
        "    if immagini_generali:\n",
        "        print(f\"    ‚Ä¢ Immagini generali: {len(immagini_generali)}\")\n",
        "\n",
        "    return output_comp, output_ess\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    docx_path = \"05.1312\\\\05.1312a-c.docx\"\n",
        "\n",
        "    estrai_metadati_completi(\n",
        "        docx_path=docx_path,\n",
        "        cartella_immagini=\"05.1312\",\n",
        "        output_completo=f\"{Path(docx_path).stem}_metadati_completi.json\",\n",
        "        output_essenziale=f\"{Path(docx_path).stem}_metadati_essenziali.json\"\n",
        "    )"
      ],
      "metadata": {
        "id": "EEsEKT810mFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizzo di LLM per arricchire i metadati\n",
        "\n",
        "Questo codice rappresenta una prova per comprendere potenzialit√† e limiti nell'utilizzo di LLM per l'estrazione di metadati partendo dalle immagini rappresentanti l'oggetto digitale e il contesto fornito dal JSON precedentemente creato.\n",
        "\n",
        "Il codice itera all'interno di una cartella dove si presuppone ci siano tutte le immagini costituenti un oggetto digitale. Manualmente bisogna selezionare la cartella e il corrispondente JSON con i metadati --> questo potrebbe essere modificato e automatizzato, facendo un match per ID tra cartella e JSON. Basta che inizialmente ci sia una strutturazione manuale.\n",
        "\n",
        "Step seguiti all'interno del codice:\n",
        "\n",
        "\n",
        "1.   **Pre-processing delle immagini**\n",
        "\n",
        "Viene utilizzata la libreria Pillow per convertire in bianco e nero le immagini e aumentarne di poco il contrasto. In questo modo si favorisce al modello una migliore lettura del contenuto. Le immagini vengono convertite in base64 prima di essere passate al LLM.\n",
        "\n",
        "2.   **Utilizzo del LLM**\n",
        "\n",
        "L'LLM utilizzato in questa prova √® claude-sonnet-4.5 interrogato via API a consumo.\n",
        "\n",
        "La strutturazione √® stata gestita attraverso un'orchestrazione di agenti per permettere la condivisione di un contesto comune.\n",
        "Gli agenti che costituiscono la struttura sono:\n",
        "\n",
        "\n",
        "                        *   Agente Metadati\n",
        "                        *   Agente Trascrizione\n",
        "                        *   Agente Regesto\n",
        "\n",
        "\n",
        "*   **Agente Metadati**\n",
        "Prende in input le immagini che costituiscono l'oggetto digitale e i metadati dal file json. Analizza le immagini ed estrae ulteriori metadati come: lingua dei documenti, tipologia di documento (lettera, diario..), se il documento √® manoscritto o stampato, le aree di testo individuate (intestazione, corpo del documento, note a margine), la presenza di abbreviazioni, elementi presenti nei documenti come bolli, timbri, presenza di sottolineature, testo barrato o in grassetto.\n",
        "\n",
        "*   **Agente Trascrizione**\n",
        "Si occupa di fornire una trascrizione del contenuto dell'oggetto digitale, prendendo in input le immagini e i metadati del JSON, assieme ai metadati estratti dal LLM in precedenza. Il contesto fornito dovrebbe aiutare l'LLM nel riconoscimento del testo. Il testo viene inserito all'interno del tag <transcription> in cui, all'interno, ci possono essere altri tag per identificare l'appartenenza del testo ad un'area ( note a margine, intestazione), oppure peculiarit√† del testo (abbreviazioni, sottolineature). Questo √® un approccio generalista al problema: la documentazione fornita √® estremamente eterogenea, scritta in diverse lingue e in diversi momenti storici.\n",
        "\n",
        "*   **Agente Regesto**\n",
        "L'agente considera la trascrizione fornita √® crea un regesto, ovvero un breve riassunto del contenuto. Anche se la trascrizione non √® completamente corretta quindi, il regesto viene creato efficacemente. L'agente possiede un few-shot prompt, in cui ho inserito due esempi di trascrizioni testuali e di regesti, in questo modo l'agente dovrebbe essere in grado di seguire le linee guida e creare un regesto secondo le modalit√† pre-fissate.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QLINl6e_7DoV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoJBwM9Hzs_b"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Any\n",
        "from dataclasses import dataclass, asdict\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "import os\n",
        "from io import BytesIO\n",
        "\n",
        "try:\n",
        "    from PIL import Image, ImageEnhance\n",
        "except ImportError:\n",
        "    raise ImportError(\"Installa Pillow: pip install Pillow\")\n",
        "\n",
        "\n",
        "class AgentType(Enum):\n",
        "    \"\"\"Tipi di agenti nel sistema\"\"\"\n",
        "    ANALYSIS = \"agente_analisi\"\n",
        "    TRANSCRIPTION = \"agente_trascrizione\"\n",
        "    REGESTO = \"agente_regesto\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ContextValue:\n",
        "    \"\"\"Rappresenta un valore nel contesto con metadati\"\"\"\n",
        "    valore: Any\n",
        "    confidence: float\n",
        "    modificato_da: str\n",
        "    timestamp: str\n",
        "    versione_precedente: Optional[Any] = None\n",
        "\n",
        "    def to_dict(self):\n",
        "        return asdict(self)\n",
        "\n",
        "\n",
        "class SharedMemory:\n",
        "    \"\"\"Memoria condivisa accessibile da tutti gli agenti\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.metadati_esterni: Dict = {}\n",
        "        self.analisi: Dict[str, ContextValue] = {}\n",
        "        self.trascrizione: Optional[str] = None\n",
        "        self.storia_modifiche: List[Dict] = []\n",
        "        self.immagini_paths: List[str] = []\n",
        "\n",
        "    def set_metadati_esterni(self, metadati: Dict):\n",
        "        \"\"\"Carica i metadati esterni dal file\"\"\"\n",
        "        self.metadati_esterni = metadati\n",
        "        self._log_modifica(\"sistema\", \"caricamento_metadati_esterni\", metadati)\n",
        "\n",
        "    def set_immagini(self, immagini_paths: List[str]):\n",
        "        \"\"\"Registra i path delle immagini dell'oggetto digitale\"\"\"\n",
        "        self.immagini_paths = immagini_paths\n",
        "        self._log_modifica(\"sistema\", \"registrazione_immagini\",\n",
        "                          {\"numero_immagini\": len(immagini_paths)})\n",
        "\n",
        "    def write(self, chiave: str, valore: Any, confidence: float,\n",
        "              agente: AgentType, note: Optional[str] = None):\n",
        "        \"\"\"Scrive o aggiorna un valore nella memoria\"\"\"\n",
        "        versione_precedente = None\n",
        "        if chiave in self.analisi:\n",
        "            versione_precedente = self.analisi[chiave].valore\n",
        "\n",
        "        context_value = ContextValue(\n",
        "            valore=valore,\n",
        "            confidence=confidence,\n",
        "            modificato_da=agente.value,\n",
        "            timestamp=datetime.now().isoformat(),\n",
        "            versione_precedente=versione_precedente\n",
        "        )\n",
        "\n",
        "        self.analisi[chiave] = context_value\n",
        "\n",
        "        self._log_modifica(\n",
        "            agente.value,\n",
        "            f\"aggiornamento_{chiave}\",\n",
        "            {\n",
        "                \"valore_nuovo\": valore,\n",
        "                \"valore_precedente\": versione_precedente,\n",
        "                \"confidence\": confidence,\n",
        "                \"note\": note\n",
        "            }\n",
        "        )\n",
        "\n",
        "    def read(self, chiave: str) -> Optional[ContextValue]:\n",
        "        \"\"\"Legge un valore dalla memoria\"\"\"\n",
        "        return self.analisi.get(chiave)\n",
        "\n",
        "    def get_all_context(self) -> Dict:\n",
        "        \"\"\"Restituisce tutto il contesto corrente\"\"\"\n",
        "        return {\n",
        "            \"metadati_esterni\": self.metadati_esterni,\n",
        "            \"analisi\": {k: v.to_dict() for k, v in self.analisi.items()},\n",
        "            \"trascrizione\": self.trascrizione,\n",
        "            \"immagini_paths\": self.immagini_paths\n",
        "        }\n",
        "\n",
        "    def _log_modifica(self, agente: str, azione: str, dettagli: Any):\n",
        "        \"\"\"Registra una modifica nella storia\"\"\"\n",
        "        self.storia_modifiche.append({\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"agente\": agente,\n",
        "            \"azione\": azione,\n",
        "            \"dettagli\": dettagli\n",
        "        })\n",
        "\n",
        "    def get_storia(self) -> List[Dict]:\n",
        "        \"\"\"Restituisce la storia completa delle modifiche\"\"\"\n",
        "        return self.storia_modifiche\n",
        "\n",
        "\n",
        "class LLMClient:\n",
        "    \"\"\"Client per interagire con API di LLM con Prompt Caching\"\"\"\n",
        "\n",
        "    def __init__(self, provider: str = \"anthropic\", api_key: Optional[str] = None,\n",
        "                 use_prompt_caching: bool = True):\n",
        "        \"\"\"\n",
        "        Inizializza il client LLM\n",
        "\n",
        "        Args:\n",
        "            provider: \"anthropic\" per Claude\n",
        "            api_key: Chiave API (se None, cerca nelle variabili d'ambiente)\n",
        "            use_prompt_caching: Se True, usa il prompt caching di Anthropic\n",
        "        \"\"\"\n",
        "        self.provider = provider\n",
        "        self.use_prompt_caching = use_prompt_caching\n",
        "\n",
        "        if provider == \"anthropic\":\n",
        "            try:\n",
        "                import anthropic\n",
        "                self.client = anthropic.Anthropic(api_key=api_key)\n",
        "                self.model = \"claude-sonnet-4-5-20250929\"\n",
        "            except ImportError:\n",
        "                raise ImportError(\"Installa: pip install anthropic\")\n",
        "        else:\n",
        "            raise ValueError(f\"Provider non supportato: {provider}\")\n",
        "\n",
        "        self.calls_count = 0\n",
        "\n",
        "        if use_prompt_caching:\n",
        "            print(\"\\nüí∞ PROMPT CACHING ATTIVO\")\n",
        "\n",
        "    def _preprocess_image(self, image_path: str, contrast_factor: float = 2.0,\n",
        "                         save_preview: bool = False, preview_folder: str = \"./preview\",\n",
        "                         max_size_mb: float = 5.0) -> bytes:\n",
        "        \"\"\"Preprocessa l'immagine: conversione in bianco e nero, aumento contrasto e resize se necessario\"\"\"\n",
        "        img = Image.open(image_path)\n",
        "\n",
        "        # Conversione in bianco e nero\n",
        "        img_bw = img.convert('L')\n",
        "\n",
        "        # Aumento contrasto\n",
        "        enhancer = ImageEnhance.Contrast(img_bw)\n",
        "        img_enhanced = enhancer.enhance(contrast_factor)\n",
        "\n",
        "        # Funzione helper per ottenere la dimensione effettiva in bytes del base64\n",
        "        def get_size_bytes(image, quality=95):\n",
        "            buffer = BytesIO()\n",
        "            image.save(buffer, format='JPEG', quality=quality)\n",
        "            jpeg_bytes = buffer.getvalue()\n",
        "            # Calcola dimensione base64 (circa 1.37x la dimensione originale)\n",
        "            base64_size = len(base64.standard_b64encode(jpeg_bytes))\n",
        "            buffer.close()\n",
        "            return base64_size, len(jpeg_bytes)\n",
        "\n",
        "        # Limite in bytes (lasciamo margine di sicurezza: 4.8MB invece di 5MB)\n",
        "        max_size_bytes = int(max_size_mb * 1024 * 1024 * 0.96)\n",
        "\n",
        "        # Resize iterativo se l'immagine supera max_size_mb\n",
        "        quality = 95\n",
        "        current_img = img_enhanced\n",
        "        base64_size, jpeg_size = get_size_bytes(current_img, quality)\n",
        "\n",
        "        if base64_size > max_size_bytes:\n",
        "            print(f\"[RESIZE] Immagine {Path(image_path).name}: {base64_size/(1024*1024):.2f}MB > {max_size_mb}MB\")\n",
        "\n",
        "            # Strategia combinata: riduci dimensioni E qualit√† in modo pi√π aggressivo\n",
        "            scale_factor = 0.9\n",
        "\n",
        "            # Prima riduci le dimensioni progressivamente\n",
        "            while base64_size > max_size_bytes and scale_factor > 0.3:\n",
        "                new_width = int(img_enhanced.width * scale_factor)\n",
        "                new_height = int(img_enhanced.height * scale_factor)\n",
        "                current_img = img_enhanced.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "\n",
        "                # Riduci anche la qualit√† se necessario\n",
        "                quality = 90 if scale_factor > 0.7 else 85 if scale_factor > 0.5 else 75\n",
        "\n",
        "                base64_size, jpeg_size = get_size_bytes(current_img, quality)\n",
        "\n",
        "                if base64_size > max_size_bytes:\n",
        "                    scale_factor -= 0.05\n",
        "\n",
        "            # Se ancora troppo grande, riduci ulteriormente la qualit√†\n",
        "            while base64_size > max_size_bytes and quality > 60:\n",
        "                quality -= 5\n",
        "                base64_size, jpeg_size = get_size_bytes(current_img, quality)\n",
        "\n",
        "            print(f\"[RESIZE] Ridotta a: {base64_size/(1024*1024):.2f}MB (qualit√†: {quality}, scala: {scale_factor:.1%})\")\n",
        "            print(f\"[RESIZE] Dimensioni: {current_img.width}x{current_img.height} (originale: {img_enhanced.width}x{img_enhanced.height})\")\n",
        "\n",
        "        # Salva preview se richiesto\n",
        "        if save_preview:\n",
        "            preview_path = Path(preview_folder)\n",
        "            preview_path.mkdir(exist_ok=True)\n",
        "            original_name = Path(image_path).stem\n",
        "            preview_file = preview_path / f\"{original_name}_preprocessed.jpg\"\n",
        "            current_img.save(preview_file, format='JPEG', quality=quality)\n",
        "            print(f\"[PREVIEW] Salvata in: {preview_file}\")\n",
        "\n",
        "        # Salva nel buffer finale\n",
        "        buffer = BytesIO()\n",
        "        current_img.save(buffer, format='JPEG', quality=quality)\n",
        "        buffer.seek(0)\n",
        "        return buffer.read()\n",
        "\n",
        "    def _load_image_base64(self, image_path: str, preprocess: bool = True,\n",
        "                          contrast_factor: float = 2.0, save_preview: bool = False,\n",
        "                          preview_folder: str = \"./preview\") -> tuple[str, str]:\n",
        "        \"\"\"Carica un'immagine, la preprocessa e la converte in base64\"\"\"\n",
        "        if preprocess:\n",
        "            image_bytes = self._preprocess_image(image_path, contrast_factor,\n",
        "                                                 save_preview, preview_folder)\n",
        "            media_type = 'image/jpeg'\n",
        "            image_data = base64.standard_b64encode(image_bytes).decode(\"utf-8\")\n",
        "        else:\n",
        "            path = Path(image_path)\n",
        "            ext = path.suffix.lower()\n",
        "            media_types = {\n",
        "                '.jpg': 'image/jpeg',\n",
        "                '.jpeg': 'image/jpeg',\n",
        "                '.png': 'image/png',\n",
        "                '.gif': 'image/gif',\n",
        "                '.webp': 'image/webp'\n",
        "            }\n",
        "            media_type = media_types.get(ext, 'image/jpeg')\n",
        "\n",
        "            with open(image_path, \"rb\") as f:\n",
        "                image_data = base64.standard_b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "        return media_type, image_data\n",
        "\n",
        "    def call_vision_api(self, prompt: str, image_paths: List[str],\n",
        "                       system_prompt: str,\n",
        "                       response_format: str = \"json\",\n",
        "                       preprocess_images: bool = True,\n",
        "                       contrast_factor: float = 2.0,\n",
        "                       save_preview: bool = False,\n",
        "                       preview_folder: str = \"./preview\") -> Dict:\n",
        "        \"\"\"\n",
        "        Chiama l'API vision con PROMPT CACHING\n",
        "\n",
        "        Args:\n",
        "            prompt: Il prompt testuale specifico dell'agente\n",
        "            image_paths: Lista di path alle immagini del manoscritto\n",
        "            system_prompt: System prompt (verr√† cachato con cache_control)\n",
        "            response_format: \"json\" o \"text\"\n",
        "            preprocess_images: Se True, converte in B&W e aumenta contrasto\n",
        "            contrast_factor: Fattore di aumento contrasto (default 2.0)\n",
        "            save_preview: Se True, salva preview delle immagini preprocessate\n",
        "            preview_folder: Cartella dove salvare le preview\n",
        "        \"\"\"\n",
        "        if self.provider == \"anthropic\":\n",
        "            return self._call_anthropic_vision(\n",
        "                prompt, image_paths, system_prompt, response_format,\n",
        "                preprocess_images, contrast_factor,\n",
        "                save_preview, preview_folder\n",
        "            )\n",
        "\n",
        "    def call_text_api(self, prompt: str, system_prompt: str,\n",
        "                     response_format: str = \"json\") -> Dict:\n",
        "        \"\"\"Chiama l'API solo testo (per il regesto)\"\"\"\n",
        "        if self.provider == \"anthropic\":\n",
        "            return self._call_anthropic_text(prompt, system_prompt, response_format)\n",
        "\n",
        "    def _call_anthropic_vision(self, prompt: str, image_paths: List[str],\n",
        "                               system_prompt: str, response_format: str,\n",
        "                               preprocess_images: bool = True,\n",
        "                               contrast_factor: float = 2.0,\n",
        "                               save_preview: bool = False,\n",
        "                               preview_folder: str = \"./preview\") -> Dict:\n",
        "        \"\"\"Chiamata specifica per Claude con PROMPT CACHING\"\"\"\n",
        "        self.calls_count += 1\n",
        "\n",
        "        print(f\"\\n[API CALL #{self.calls_count}] Chiamata vision API\")\n",
        "        print(f\"[LLM] Preprocessing: {'ATTIVO' if preprocess_images else 'DISATTIVO'}\")\n",
        "        if preprocess_images:\n",
        "            print(f\"[LLM] Contrasto: {contrast_factor}x\")\n",
        "        if self.use_prompt_caching:\n",
        "            print(f\"[LLM] üíæ Prompt Caching: ATTIVO\")\n",
        "\n",
        "        # Costruisci content con tutte le immagini\n",
        "        content = []\n",
        "\n",
        "        # Aggiungi tutte le immagini\n",
        "        for i, img_path in enumerate(image_paths):\n",
        "            media_type, image_data = self._load_image_base64(\n",
        "                img_path,\n",
        "                preprocess=preprocess_images,\n",
        "                contrast_factor=contrast_factor,\n",
        "                save_preview=save_preview,\n",
        "                preview_folder=preview_folder\n",
        "            )\n",
        "\n",
        "            image_block = {\n",
        "                \"type\": \"image\",\n",
        "                \"source\": {\n",
        "                    \"type\": \"base64\",\n",
        "                    \"media_type\": media_type,\n",
        "                    \"data\": image_data\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # CACHE_CONTROL: Aggiungi cache all'ULTIMA immagine\n",
        "            if self.use_prompt_caching and i == len(image_paths) - 1:\n",
        "                image_block[\"cache_control\"] = {\"type\": \"ephemeral\"}\n",
        "                print(f\"[LLM] ‚úì Cache abilitata per {len(image_paths)} immagini\")\n",
        "\n",
        "            content.append(image_block)\n",
        "            print(f\"[LLM] Immagine {i+1}/{len(image_paths)}: {Path(img_path).name}\")\n",
        "\n",
        "        # Aggiungi il prompt alla fine\n",
        "        content.append({\n",
        "            \"type\": \"text\",\n",
        "            \"text\": prompt\n",
        "        })\n",
        "\n",
        "        # System prompt con cache_control\n",
        "        system_blocks = [{\n",
        "            \"type\": \"text\",\n",
        "            \"text\": system_prompt\n",
        "        }]\n",
        "\n",
        "        # CACHE_CONTROL sul system prompt\n",
        "        if self.use_prompt_caching:\n",
        "            system_blocks[0][\"cache_control\"] = {\"type\": \"ephemeral\"}\n",
        "            print(f\"[LLM] ‚úì Cache abilitata per system prompt\")\n",
        "\n",
        "        messages = [{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": content\n",
        "        }]\n",
        "\n",
        "        # Chiamata API\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=8192,\n",
        "            temperature=0,\n",
        "            system=system_blocks,\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        content_text = response.content[0].text\n",
        "\n",
        "        if response_format == \"json\":\n",
        "            content_text = content_text.strip()\n",
        "            if content_text.startswith(\"```json\"):\n",
        "                content_text = content_text[7:]\n",
        "            if content_text.endswith(\"```\"):\n",
        "                content_text = content_text[:-3]\n",
        "            return json.loads(content_text.strip())\n",
        "\n",
        "        return {\"text\": content_text}\n",
        "\n",
        "    def _call_anthropic_text(self, prompt: str, system_prompt: str,\n",
        "                            response_format: str) -> Dict:\n",
        "        \"\"\"Chiamata specifica per Claude solo testo\"\"\"\n",
        "        self.calls_count += 1\n",
        "        print(f\"\\n[API CALL #{self.calls_count}] Chiamata text API (regesto)\")\n",
        "\n",
        "        messages = [{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }]\n",
        "\n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=4096,\n",
        "            temperature=0,\n",
        "            system=system_prompt,\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        content = response.content[0].text\n",
        "\n",
        "        if response_format == \"json\":\n",
        "            content = content.strip()\n",
        "            if content.startswith(\"```json\"):\n",
        "                content = content[7:]\n",
        "            if content.endswith(\"```\"):\n",
        "                content = content[:-3]\n",
        "            return json.loads(content.strip())\n",
        "\n",
        "        return {\"text\": content}\n",
        "\n",
        "\n",
        "class AgentAnalysis:\n",
        "    \"\"\"Agente per l'analisi del manoscritto\"\"\"\n",
        "\n",
        "    def __init__(self, memory: SharedMemory, llm_client: LLMClient):\n",
        "        self.memory = memory\n",
        "        self.llm = llm_client\n",
        "        self.agent_type = AgentType.ANALYSIS\n",
        "\n",
        "    def analyze(self) -> Dict:\n",
        "        \"\"\"Analizza il manoscritto ed estrae informazioni contestuali\"\"\"\n",
        "        print(f\"\\n[{self.agent_type.value}] Inizio analisi del manoscritto...\")\n",
        "\n",
        "        immagini = self.memory.immagini_paths\n",
        "        if not immagini:\n",
        "            raise ValueError(\"Nessuna immagine registrata nella memoria\")\n",
        "\n",
        "        print(f\"[{self.agent_type.value}] Analizzando {len(immagini)} immagini\")\n",
        "\n",
        "        metadati = self.memory.metadati_esterni\n",
        "\n",
        "        # System prompt (verr√† cachato!)\n",
        "        system_prompt = \"\"\"Sei un assistente specializzato nell'analisi e trascrizione di materiale archivistico manoscritto e/o stampato. Sei specializzato nell'analisi di materiale eterogeneo proveniente da diverse epoche storiche: lettere, quaderni, appunti, diari.\"\"\"\n",
        "\n",
        "        # User prompt specifico\n",
        "        prompt = self._build_analysis_prompt(metadati, len(immagini))\n",
        "\n",
        "        try:\n",
        "            preprocess = True\n",
        "            contrast = 2.0\n",
        "\n",
        "            if hasattr(self, '_orchestrator_settings'):\n",
        "                preprocess = self._orchestrator_settings.get('preprocess', True)\n",
        "                contrast = self._orchestrator_settings.get('contrast', 2.0)\n",
        "\n",
        "            response = self.llm.call_vision_api(\n",
        "                prompt=prompt,\n",
        "                image_paths=immagini,\n",
        "                system_prompt=system_prompt,\n",
        "                response_format=\"json\",\n",
        "                preprocess_images=preprocess,\n",
        "                contrast_factor=contrast\n",
        "            )\n",
        "\n",
        "            print(f\"[{self.agent_type.value}] Risposta LLM ricevuta\")\n",
        "\n",
        "            self._write_results_to_memory(response)\n",
        "\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[{self.agent_type.value}] ‚ùå Errore durante l'analisi: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _build_analysis_prompt(self, metadati: Dict, num_immagini: int) -> str:\n",
        "        \"\"\"Costruisce il prompt per l'analisi\"\"\"\n",
        "        base_prompt = f\"\"\"Sei un assistente specializzato nell'analisi e trascrizione di materiale archivistico manoscritto e/o stampato. Sei specializzato nell'analisi di materiale eterogeneo proveniente da diverse epoche storiche: lettere, quaderni, appunti, diari.\n",
        "\n",
        "‚ö†Ô∏è IMPORTANTE: Stai analizzando {num_immagini} immagine/i che costituiscono UN UNICO OGGETTO DIGITALE.\n",
        "Le immagini possono rappresentare:\n",
        "- Pi√π pagine dello stesso documento (es: pagina 1 e pagina 2 di una lettera)\n",
        "- Fronte e retro di un foglio\n",
        "- Documento principale + busta\n",
        "- Documento principale + allegati\n",
        "\n",
        "La tua analisi deve riferirsi all'INTERO oggetto digitale, considerando TUTTE le immagini nel loro insieme.\n",
        "\n",
        "CONTESTO ESTERNO DISPONIBILE:\n",
        "{json.dumps(metadati, indent=2, ensure_ascii=False)}\n",
        "\n",
        "TASK: Analizza TUTTE le immagini e determina (per l'intero oggetto digitale):\n",
        "1. **lingua**: La lingua principale del documento (es: latino, volgare toscano, italiano antico, latino medievale, etc.)\n",
        "2. **tipologia_documento**: Il tipo di documento (es: lettera privata, diario, registro commerciale, atto notarile, etc.)\n",
        "5. **abbreviazioni**: Lista di TUTTE le abbreviazioni trovate nelle varie immagini con relativo scioglimento.\n",
        "6. **aree_del_testo**: Aree del testo individuate in TUTTE le immagini (es: intestazione, note a margine, corpo del testo, busta, etc.)\n",
        "7. **descrizione_elementi**: Note descrittive su elementi presenti in TUTTE le pagine/immagini (timbri, bolli, elementi di carta intestata, annotazioni archivistiche presenti).\n",
        "8. **particolarit√†_linguistiche**: Dizionario che come chiave possiede il termine / i termini sottolineati, barrati, o scritti in grassetto (da TUTTE le immagini) e come valore la tipologia di particolarit√† linguistica riscontrata.\n",
        "9. **composizione_oggetto**: Descrizione di come le immagini si relazionano tra loro (es: \"immagine 1: pagina 1 della lettera, immagine 2: pagina 2 della lettera\", oppure \"immagine 1: fronte, immagine 2: retro con indirizzo del destinatario\")\n",
        "\n",
        "Per ogni campo, fornisci anche un **confidence_score** tra 0 e 1.\n",
        "\n",
        "FORMATO OUTPUT (JSON):\n",
        "{{\n",
        "  \"lingua\": {{\n",
        "    \"valore\": \"...\",\n",
        "    \"confidence\": 0.85,\n",
        "    \"note\": \"...\"\n",
        "  }},\n",
        "  \"tipologia_documento\": {{\n",
        "    \"valore\": \"...\",\n",
        "    \"confidence\": 0.90,\n",
        "    \"note\": \"...\"\n",
        "  }},\n",
        "  \"natura_documento\": {{\n",
        "    \"valore\": \"...\",\n",
        "    \"confidence\": 0.75,\n",
        "    \"note\": \"...\"\n",
        "  }},\n",
        "  \"tipo_scrittura\": {{\n",
        "    \"valore\": \"...\",\n",
        "    \"confidence\": 0.75,\n",
        "    \"note\": \"...\"\n",
        "  }},\n",
        "  \"abbreviazioni\": {{\n",
        "    \"valore\": [\"...\", \"...\"],\n",
        "    \"confidence\": 0.80,\n",
        "    \"note\": \"...\"\n",
        "  }},\n",
        "  \"aree_del_testo\": {{\n",
        "    \"valore\": [\"...\", \"...\"],\n",
        "    \"confidence\": 0.85,\n",
        "    \"note\": \"...\"\n",
        "  }},\n",
        "  \"descrizione_elementi\": {{\n",
        "    \"valore\": [\"...\", \"...\"],\n",
        "    \"confidence\": 0.85,\n",
        "    \"note\": \"...\"\n",
        "  }},\n",
        "  \"particolarit√†_linguistiche\": {{\n",
        "    \"valore\": {{\"termine\": \"tipo_particolarit√†\", ...}},\n",
        "    \"confidence\": 0.85,\n",
        "    \"note\": \"...\"\n",
        "  }},\n",
        "  \"composizione_oggetto\": {{\n",
        "    \"valore\": \"descrizione della relazione tra le immagini...\",\n",
        "    \"confidence\": 0.90,\n",
        "    \"note\": \"...\"\n",
        "  }}\n",
        "}}\n",
        "\n",
        "Rispondi SOLO con il JSON, senza altro testo.\"\"\"\n",
        "\n",
        "        return base_prompt\n",
        "\n",
        "    def _write_results_to_memory(self, response: Dict):\n",
        "        \"\"\"Scrive i risultati dell'analisi nella memoria condivisa\"\"\"\n",
        "        for chiave, dati in response.items():\n",
        "            if chiave == \"osservazioni\":\n",
        "                continue\n",
        "\n",
        "            if isinstance(dati, dict) and \"valore\" in dati:\n",
        "                self.memory.write(\n",
        "                    chiave=chiave,\n",
        "                    valore=dati[\"valore\"],\n",
        "                    confidence=dati.get(\"confidence\", 0.5),\n",
        "                    agente=self.agent_type,\n",
        "                    note=dati.get(\"note\")\n",
        "                )\n",
        "\n",
        "        print(f\"[{self.agent_type.value}] Risultati scritti in memoria\")\n",
        "\n",
        "\n",
        "class AgentTranscription:\n",
        "    \"\"\"Agente per la trascrizione del manoscritto con validazione contro metadati esterni\"\"\"\n",
        "\n",
        "    def __init__(self, memory: SharedMemory, llm_client: LLMClient):\n",
        "        self.memory = memory\n",
        "        self.llm = llm_client\n",
        "        self.agent_type = AgentType.TRANSCRIPTION\n",
        "\n",
        "    def transcribe(self) -> Dict:\n",
        "        \"\"\"Trascrive il manoscritto usando il contesto dalla memoria condivisa e validando contro metadati esterni\"\"\"\n",
        "        print(f\"\\n[{self.agent_type.value}] Inizio trascrizione...\")\n",
        "\n",
        "        immagini = self.memory.immagini_paths\n",
        "        if not immagini:\n",
        "            raise ValueError(\"Nessuna immagine registrata nella memoria\")\n",
        "\n",
        "        print(f\"[{self.agent_type.value}] Trascrivendo {len(immagini)} immagini\")\n",
        "\n",
        "        context = self.memory.get_all_context()\n",
        "\n",
        "        print(f\"[{self.agent_type.value}] Contesto utilizzato:\")\n",
        "        for k, v in context['analisi'].items():\n",
        "            print(f\"  - {k}: {v['valore']} (confidence: {v['confidence']:.2f})\")\n",
        "\n",
        "        # Stampa metadati esterni se presenti\n",
        "        if context['metadati_esterni']:\n",
        "            print(f\"[{self.agent_type.value}] Metadati esterni (VINCOLANTI):\")\n",
        "            for k, v in context['metadati_esterni'].items():\n",
        "                print(f\"  - {k}: {v}\")\n",
        "\n",
        "        # System prompt (STESSO dell'analisi - verr√† letto dalla cache!)\n",
        "        system_prompt = \"\"\"Sei un assistente specializzato nell'analisi e trascrizione di materiale archivistico manoscritto e/o stampato.\n",
        "        Sei specializzato nell'analisi di materiale eterogeneo proveniente da diverse epoche storiche: lettere, quaderni, appunti, diari.\"\"\"\n",
        "\n",
        "        prompt = self._build_transcription_prompt(context)\n",
        "\n",
        "        try:\n",
        "            preprocess = True\n",
        "            contrast = 2.0\n",
        "            save_preview = False\n",
        "            preview_folder = \"./preview\"\n",
        "\n",
        "            if hasattr(self, '_orchestrator_settings'):\n",
        "                preprocess = self._orchestrator_settings.get('preprocess', True)\n",
        "                contrast = self._orchestrator_settings.get('contrast', 2.0)\n",
        "                save_preview = self._orchestrator_settings.get('save_preview', False)\n",
        "                preview_folder = self._orchestrator_settings.get('preview_folder', './preview')\n",
        "\n",
        "            # STESSE IMMAGINI dell'analisi - verranno lette dalla cache!\n",
        "            response = self.llm.call_vision_api(\n",
        "                prompt=prompt,\n",
        "                image_paths=immagini,\n",
        "                system_prompt=system_prompt,\n",
        "                response_format=\"json\",\n",
        "                preprocess_images=preprocess,\n",
        "                contrast_factor=contrast,\n",
        "                save_preview=save_preview,\n",
        "                preview_folder=preview_folder\n",
        "            )\n",
        "\n",
        "            print(f\"[{self.agent_type.value}] Risposta LLM ricevuta\")\n",
        "\n",
        "            # Salva la trascrizione\n",
        "            trascrizione = response.get(\"trascrizione\", \"\")\n",
        "            self.memory.trascrizione = trascrizione\n",
        "\n",
        "            # Log eventuali correzioni applicate\n",
        "            if response.get(\"correzioni_applicate\"):\n",
        "                print(f\"[{self.agent_type.value}] ‚ö†Ô∏è Correzioni applicate basate su metadati esterni:\")\n",
        "                for correzione in response[\"correzioni_applicate\"]:\n",
        "                    print(f\"  ‚Ä¢ {correzione}\")\n",
        "\n",
        "            print(f\"[{self.agent_type.value}] Trascrizione completata\")\n",
        "\n",
        "            return {\n",
        "                \"stato\": \"completato\",\n",
        "                \"trascrizione\": trascrizione,\n",
        "                \"note_trascrittore\": response.get(\"note\", \"\"),\n",
        "                \"correzioni_applicate\": response.get(\"correzioni_applicate\", []),\n",
        "                \"contraddizioni_rilevate\": response.get(\"contraddizioni_rilevate\", [])\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[{self.agent_type.value}] ‚ùå Errore: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _build_transcription_prompt(self, context: Dict) -> str:\n",
        "        \"\"\"Costruisce il prompt per la trascrizione con validazione contro metadati esterni\"\"\"\n",
        "        analisi = context['analisi']\n",
        "        metadati_esterni = context['metadati_esterni']\n",
        "        num_immagini = len(context['immagini_paths'])\n",
        "\n",
        "        prompt = f\"\"\"Trascrivi accuratamente il testo di TUTTE le {num_immagini} immagini che costituiscono l'oggetto digitale.\n",
        "\n",
        "‚ö†Ô∏è IMPORTANTE: Le immagini formano UN UNICO OGGETTO DIGITALE.\n",
        "Devi fornire UNA TRASCRIZIONE UNIFICATA che consideri tutte le immagini nel loro ordine logico.\n",
        "\n",
        "============================================================\n",
        "GERARCHIA DELLE FONTI PER LA TRASCRIZIONE\n",
        "============================================================\n",
        "\n",
        "‚ö†Ô∏è REGOLA FONDAMENTALE - VALIDAZIONE CON METADATI ESTERNI:\n",
        "\n",
        "I METADATI ESTERNI sono stati inseriti MANUALMENTE da archivisti professionisti.\n",
        "Questi metadati hanno PRIORIT√Ä ASSOLUTA e sono VINCOLANTI per la trascrizione.\n",
        "\n",
        "üîµ METADATI ESTERNI (fonte primaria - VINCOLANTI):\n",
        "\"\"\"\n",
        "\n",
        "        # Lista i metadati esterni disponibili\n",
        "        if metadati_esterni:\n",
        "            prompt += \"\\nI seguenti metadati DEVONO essere rispettati nella trascrizione:\\n\"\n",
        "            for chiave, valore in metadati_esterni.items():\n",
        "                prompt += f\"  ‚Ä¢ {chiave}: {valore}\\n\"\n",
        "\n",
        "            prompt += \"\"\"\n",
        "üìã REGOLE DI VALIDAZIONE OBBLIGATORIE:\n",
        "\n",
        "1. **AUTORE/MITTENTE**:\n",
        "   - Se presente nei metadati esterni ‚Üí la firma nel documento DEVE corrispondere\n",
        "   - Se trascrivendo la firma trovi un nome DIVERSO ‚Üí CORREGGI usando i metadati esterni\n",
        "   - Aggiungi una nota nel campo \"correzioni_applicate\"\n",
        "\n",
        "2. **DATA**:\n",
        "   - Se presente nei metadati esterni ‚Üí la data nel documento DEVE corrispondere\n",
        "   - Se trascrivendo la data trovi una data DIVERSA ‚Üí CORREGGI usando i metadati esterni\n",
        "   - IMPORTANTE: Potrebbero esserci variazioni di formato (es. \"16 dicembre 1843\" vs \"16/12/1843\")\n",
        "     ma il giorno/mese/anno devono coincidere\n",
        "   - Se la data √® parzialmente illeggibile, usa i metadati esterni per completarla\n",
        "   - Aggiungi una nota nel campo \"correzioni_applicate\"\n",
        "\n",
        "3. **ALTRI CAMPI**:\n",
        "   - Se altri campi sono presenti nei metadati esterni (es. luogo, destinatario)\n",
        "     e sono visibili nel documento ‚Üí devono essere coerenti\n",
        "   - In caso di discrepanza ‚Üí PREVALGONO i metadati esterni\n",
        "\n",
        "‚ö†Ô∏è COME APPLICARE LE CORREZIONI:\n",
        "\n",
        "Se devi correggere un elemento nella trascrizione basandoti sui metadati esterni:\n",
        "- Trascrivi usando il valore dei METADATI ESTERNI\n",
        "- Aggiungi un commento XML: <!-- CORRETTO da metadati esterni: visto \"[testo_visto]\", usato \"[testo_corretto]\" -->\n",
        "- Registra la correzione nel campo \"correzioni_applicate\"\n",
        "\n",
        "ESEMPIO:\n",
        "Se vedi nella firma \"pietro giordini\" ma i metadati esterni dicono autore=\"Pietro Giordani\":\n",
        "<sender>Pietro Giordani<!-- CORRETTO da metadati esterni: visto \"pietro giordini\" --></sender>\n",
        "\n",
        "Se vedi una data \"15 dicembre\" ma i metadati esterni dicono data=\"16 dicembre 1843\":\n",
        "<date>16 dicembre 1843<!-- CORRETTO da metadati esterni: visto \"15 dicembre\" --></date>\n",
        "\n",
        "\"\"\"\n",
        "        else:\n",
        "            prompt += \"\\nNessun metadato esterno disponibile - trascrivi fedelmente ci√≤ che vedi.\\n\"\n",
        "\n",
        "        prompt += \"\"\"\n",
        "============================================================\n",
        "CONTESTO PALEOGRAFICO E LINGUISTICO:\n",
        "============================================================\n",
        "\n",
        "\"\"\"\n",
        "        prompt += json.dumps(analisi, indent=2, ensure_ascii=False) + \"\\n\"\n",
        "\n",
        "        if metadati_esterni:\n",
        "            prompt += \"\"\"\n",
        "============================================================\n",
        "METADATI ESTERNI (VINCOLANTI):\n",
        "============================================================\n",
        "\n",
        "\"\"\"\n",
        "            prompt += json.dumps(metadati_esterni, indent=2, ensure_ascii=False) + \"\\n\"\n",
        "\n",
        "        prompt += \"\"\"\n",
        "============================================================\n",
        "LINEE GUIDA PER LA TRASCRIZIONE:\n",
        "============================================================\n",
        "\n",
        "Analizza l'immagine nella sua completezza e identifica le diverse aree di testo. Poi segui queste linee guida:\n",
        "\n",
        "**STRUTTURA E TAG:**\n",
        "- Le annotazioni archivistiche a matita (es. 05.1063) devono essere trascritte e racchiuse all'interno di <archivaldescription>\n",
        "- Le note autografe a margine del testo devono essere racchiuse all'interno di <marginalia>. Le note autografe potrebbero anche essere scritte ruotate di 90 gradi rispetto al corpo del testo.\n",
        "- La trascrizione del testo deve essere racchiusa all'interno di <transcription>. Questo tag contiene l'intero testo autografo da TUTTE le immagini.\n",
        "- Le parole sottolineate devono essere racchiuse all'interno del tag <s>\n",
        "- Le parole barrate all'interno del tag <del>\n",
        "- Le parole in grassetto all'interno del tag <b>\n",
        "- Le abbreviazioni devono essere taggate all'interno del tag <choice>, dentro a questo tag utilizza <abbr> per contenere il testo dell'abbreviazione e <expan> contiene la versione estesa dell'abbreviazione.\n",
        "- Se ci sono pi√π pagine, mantieni la sequenza logica e indica chiaramente il passaggio da una pagina all'altra con <!-- Pagina N -->\n",
        "\n",
        "**SE IL TESTO √à UNA LETTERA:**\n",
        "Devono essere inseriti dei tag che vanno ad identificare:\n",
        "- Il mittente <sender> - generalmente √® l'autore della lettera. La firma del mittente generalmente si trova in basso, alla fine della lettera\n",
        "  ‚ö†Ô∏è SE presente nei metadati esterni come \"autore\" ‚Üí DEVE corrispondere, altrimenti CORREGGI\n",
        "- Il destinatario <recipient> - generalmente si trova all'inizio della lettera, oppure sulla busta/retro\n",
        "- La data di stesura della lettera <date>\n",
        "  ‚ö†Ô∏è SE presente nei metadati esterni come \"data di creazione\" ‚Üí DEVE corrispondere, altrimenti CORREGGI\n",
        "- Il luogo di spedizione <place_sender> - generalmente si trova all'inizio della lettera, vicino alla data\n",
        "- Il luogo di arrivo <place_recipient> - generalmente questo dato √® presente sulla busta o sul retro\n",
        "\n",
        "Se uno di questi elementi non √® presente nel documento che stai analizzando, non inserirlo. Non inventare contenuto.\n",
        "\n",
        "**FEDELT√Ä AL TESTO:**\n",
        "1. La trascrizione deve essere semi-diplomatica. Mantieni massima fedelt√† al testo originale\n",
        "2. Se sono presenti errori di ortografia, non correggerli (TRANNE se contrastano con metadati esterni vincolanti)\n",
        "3. Espandi le abbreviazioni standard del periodo tra parentesi quadre [espansione]\n",
        "4. Segna passaggi illeggibili con [...]\n",
        "5. Mantieni la punteggiatura originale dove possibile\n",
        "6. Indica incertezze con (?) dopo la parola\n",
        "7. Se ci sono pi√π immagini/pagine, trascrivi tutto in sequenza mantenendo l'ordine logico\n",
        "\n",
        "**VALIDAZIONE E CORREZIONE:**\n",
        "Durante la trascrizione, confronta continuamente ci√≤ che vedi con i metadati esterni.\n",
        "Se trovi DISCREPANZE su elementi chiave (autore, data), applica la CORREZIONE come spiegato sopra.\n",
        "\n",
        "============================================================\n",
        "FORMATO OUTPUT (JSON):\n",
        "============================================================\n",
        "\n",
        "{\n",
        "  \"trascrizione\": \"Il testo trascritto completo da tutte le immagini con tag XML...\",\n",
        "  \"note\": \"Eventuali osservazioni sulla trascrizione\",\n",
        "  \"correzioni_applicate\": [\n",
        "    \"Firma corretta da 'pietro giordini' a 'Pietro Giordani' (metadati esterni)\",\n",
        "    \"Data corretta da '15 dicembre' a '16 dicembre 1843' (metadati esterni)\"\n",
        "  ],\n",
        "  \"contraddizioni_rilevate\": [\n",
        "    {\n",
        "      \"campo\": \"autore\",\n",
        "      \"valore_metadati_esterni\": \"Pietro Giordani\",\n",
        "      \"valore_visto_documento\": \"pietro giordini\",\n",
        "      \"azione\": \"corretto_con_metadati_esterni\",\n",
        "      \"confidence\": 0.95\n",
        "    }\n",
        "  ],\n",
        "  \"aree_incerte\": [\"riga 3-5: scrittura sbiadita\", \"...\"]\n",
        "}\n",
        "\n",
        "‚ö†Ô∏è IMPORTANTE:\n",
        "- Se applichi correzioni basate su metadati esterni, compila \"correzioni_applicate\" E \"contraddizioni_rilevate\"\n",
        "- Se non ci sono correzioni, lascia \"correzioni_applicate\" come array vuoto []\n",
        "- Se non ci sono contraddizioni rispetto all'analisi paleografica, lascia \"contraddizioni_rilevate\" come array vuoto []\n",
        "\n",
        "Rispondi SOLO con il JSON, senza altro testo.\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "class AgentRegesto:\n",
        "    \"\"\"Agente per la creazione del regesto con gerarchia epistemica delle fonti\"\"\"\n",
        "\n",
        "    def __init__(self, memory: SharedMemory, llm_client: LLMClient):\n",
        "        self.memory = memory\n",
        "        self.llm = llm_client\n",
        "        self.agent_type = AgentType.REGESTO\n",
        "\n",
        "    def crea_regesto(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Crea il regesto del documento basandosi su una gerarchia epistemica delle fonti\n",
        "\n",
        "        Usa solo text API con gerarchia esplicita delle fonti per massima efficienza.\n",
        "        Non usa vision API per ridurre i costi - si affida alla gerarchia epistemica.\n",
        "\n",
        "        Returns:\n",
        "            Dict con stato, regesto, note e fonti utilizzate\n",
        "        \"\"\"\n",
        "        print(f\"\\n[{self.agent_type.value}] Inizio creazione regesto...\")\n",
        "\n",
        "        context = self.memory.get_all_context()\n",
        "\n",
        "        if not context.get('trascrizione'):\n",
        "            raise ValueError(\"Impossibile creare regesto: trascrizione non disponibile\")\n",
        "\n",
        "        # System prompt\n",
        "        system_prompt = \"\"\"Sei un archivista esperto nella creazione di regesti per documenti storici.\n",
        "Hai accesso a multiple fonti di informazione con diversi livelli di affidabilit√†.\"\"\"\n",
        "\n",
        "        prompt = self._build_regesto_prompt_con_gerarchia(context)\n",
        "\n",
        "        try:\n",
        "            print(f\"[{self.agent_type.value}] Creazione regesto con GERARCHIA EPISTEMICA (solo text)\")\n",
        "\n",
        "            response = self.llm.call_text_api(\n",
        "                prompt=prompt,\n",
        "                system_prompt=system_prompt,\n",
        "                response_format=\"json\"\n",
        "            )\n",
        "\n",
        "            regesto = response.get(\"regesto\", \"\")\n",
        "\n",
        "            print(f\"[{self.agent_type.value}] Regesto creato ({len(regesto)} caratteri)\")\n",
        "\n",
        "            # Stampa le fonti utilizzate se presenti\n",
        "            if \"fonti_utilizzate\" in response:\n",
        "                print(f\"[{self.agent_type.value}] Fonti utilizzate:\")\n",
        "                for campo, fonte in response[\"fonti_utilizzate\"].items():\n",
        "                    print(f\"  ‚Ä¢ {campo}: {fonte}\")\n",
        "\n",
        "            self.memory._log_modifica(\n",
        "                agente=self.agent_type.value,\n",
        "                azione=\"creazione_regesto\",\n",
        "                dettagli={\n",
        "                    \"lunghezza\": len(regesto),\n",
        "                    \"metodo\": \"gerarchia_epistemica\",\n",
        "                    \"fonti_utilizzate\": response.get(\"fonti_utilizzate\", {})\n",
        "                }\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                \"stato\": \"completato\",\n",
        "                \"regesto\": regesto,\n",
        "                \"note\": response.get(\"note\", \"\"),\n",
        "                \"metodo\": \"gerarchia_epistemica\",\n",
        "                \"fonti_utilizzate\": response.get(\"fonti_utilizzate\", {})\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[{self.agent_type.value}] ‚ùå Errore: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _build_regesto_prompt_con_gerarchia(self, context: Dict) -> str:\n",
        "        \"\"\"Costruisce il prompt con GERARCHIA EPISTEMICA ESPLICITA delle fonti\"\"\"\n",
        "\n",
        "        prompt = \"\"\"Sei un archivista esperto nella creazione di regesti per documenti storici.\n",
        "\n",
        "‚ö†Ô∏è GERARCHIA DELLE FONTI (VINCOLANTE):\n",
        "\n",
        "Le informazioni che ti fornisco hanno DIVERSI LIVELLI DI AFFIDABILIT√Ä.\n",
        "Devi rispettare RIGOROSAMENTE questa gerarchia quando crei il regesto:\n",
        "\n",
        "LIVELLO 1 - FONTI PRIMARIE (massima affidabilit√†):\n",
        "\n",
        "   A) METADATI ESTERNI (inseriti manualmente da archivisti)\n",
        "      ‚Üí autore, data, luogo SE presenti\n",
        "      ‚Üí Provengono da inventari archivistici professionali\n",
        "      ‚Üí PRIORIT√Ä ASSOLUTA per questi campi\n",
        "\n",
        "   B) ANALISI PALEOGRAFICA E DOCUMENTARIA (analisi specialistica)\n",
        "      ‚Üí tipologia_documento, composizione_oggetto, aree_del_testo, lingua\n",
        "      ‚Üí Provengono da analisi visiva specialistica del manoscritto\n",
        "      ‚Üí Include un punteggio di confidence (0-1)\n",
        "      ‚Üí Se confidence ‚â• 0.75 ‚Üí alta affidabilit√†\n",
        "      ‚Üí Se confidence < 0.6 ‚Üí usa con cautela\n",
        "\n",
        "LIVELLO 2 - FONTI DI SUPPORTO (potenzialmente rumorose):\n",
        "\n",
        "   A) TAG XML NELLA TRASCRIZIONE (struttura affidabile)\n",
        "      ‚Üí <sender>, <recipient>, <date>, <place_sender>, <place_recipient>\n",
        "      ‚Üí Questi tag sono il risultato di una trascrizione strutturata\n",
        "      ‚Üí Pi√π affidabili del testo libero ma meno dei metadati esterni\n",
        "\n",
        "   B) TRASCRIZIONE TESTO LIBERO (pu√≤ contenere errori)\n",
        "      ‚Üí Il testo continuo della trascrizione\n",
        "      ‚Üí Pu√≤ contenere errori di riconoscimento del testo manoscritto\n",
        "      ‚Üí USA SOLO per comprendere il contenuto tematico\n",
        "      ‚Üí NON dedurre nomi, date o ruoli SOLO dal testo libero\n",
        "\n",
        "REGOLE DI DECISIONE VINCOLANTI:\n",
        "\n",
        "1. MITTENTE:\n",
        "   1¬∞ Cerca in METADATI ESTERNI (campo \"autore\")\n",
        "   2¬∞ Se assente, cerca tag XML <sender> nella TRASCRIZIONE\n",
        "   3¬∞ Se assente, estrai con CAUTELA dal testo libero\n",
        "   4¬∞ Se impossibile determinare con certezza, ometti o usa \"autore sconosciuto\"\n",
        "\n",
        "2. DESTINATARIO:\n",
        "   1¬∞ Cerca in METADATI ESTERNI (se presente)\n",
        "   2¬∞ Se assente, cerca tag XML <recipient> nella TRASCRIZIONE\n",
        "   3¬∞ Se assente, estrai con CAUTELA dal testo libero\n",
        "   4¬∞ Se impossibile determinare con certezza, ometti\n",
        "\n",
        "3. DATA:\n",
        "   1¬∞ Cerca in METADATI ESTERNI (campo \"data di creazione\")\n",
        "   2¬∞ Se assente, cerca tag XML <date> nella TRASCRIZIONE\n",
        "   3¬∞ Se assente, estrai con CAUTELA dal testo libero\n",
        "   4¬∞ Se impossibile determinare con certezza, ometti o usa \"data incerta\"\n",
        "\n",
        "4. LUOGO:\n",
        "   1¬∞ Cerca in METADATI ESTERNI (se presente)\n",
        "   2¬∞ Se assente, cerca tag XML <place_sender> nella TRASCRIZIONE\n",
        "   3¬∞ Se assente, estrai con CAUTELA dal testo libero\n",
        "   4¬∞ Se impossibile determinare con certezza, ometti\n",
        "\n",
        "5. TIPOLOGIA DOCUMENTO:\n",
        "   ‚Üí Usa ANALISI PALEOGRAFICA (campo \"tipologia_documento\")\n",
        "   ‚Üí Se confidence ‚â• 0.75, usa con fiducia\n",
        "   ‚Üí Se confidence < 0.6, verifica coerenza con trascrizione\n",
        "\n",
        "6. CONTENUTO/TEMA:\n",
        "   ‚Üí Usa la TRASCRIZIONE (√® affidabile per il contenuto generale)\n",
        "   ‚Üí Sintetizza il messaggio principale\n",
        "   ‚Üí Identifica richieste, informazioni o riferimenti importanti\n",
        "\n",
        "‚ö†Ô∏è IN CASO DI CONFLITTO TRA FONTI:\n",
        "   La priorit√† √® SEMPRE:\n",
        "   1¬∞ METADATI ESTERNI\n",
        "   2¬∞ ANALISI PALEOGRAFICA (se confidence ‚â• 0.75)\n",
        "   3¬∞ TAG XML TRASCRIZIONE\n",
        "   4¬∞ TESTO LIBERO TRASCRIZIONE\n",
        "\n",
        "‚ö†Ô∏è GESTIONE DELL'INCERTEZZA:\n",
        "   - Se confidence < 0.6 ‚Üí usa formulazioni caute (\"probabilmente\", \"sembra\")\n",
        "   - Se informazione mancante in fonti primarie ‚Üí preferisci omettere piuttosto che inventare\n",
        "   - Se devi usare solo testo libero ‚Üí segnala nelle note\n",
        "\n",
        "Un REGESTO √® una descrizione sintetica ma completa del contenuto di un documento, che include:\n",
        "- Chi scrive a chi (mittente e destinatario)\n",
        "- Quando √® stato scritto\n",
        "- Di cosa parla (tema principale)\n",
        "- Eventuali richieste, informazioni importanti o riferimenti significativi\n",
        "\n",
        "Il regesto deve essere:\n",
        "- Chiaro, conciso e informativo\n",
        "- Scritto in terza persona\n",
        "- Massimo 100 parole\n",
        "- Basato RIGOROSAMENTE sulla gerarchia delle fonti\n",
        "\n",
        "============================================================\n",
        "ESEMPI DI REGESTI CORRETTI:\n",
        "============================================================\n",
        "\n",
        "--- ESEMPIO 1 ---\n",
        "\n",
        "METADATI ESTERNI (fonte primaria):\n",
        "{\n",
        "  \"autore\": \"Pietro Giordani\",\n",
        "  \"data di creazione\": \"16 dicembre 1843\"\n",
        "}\n",
        "\n",
        "ANALISI PALEOGRAFICA (fonte primaria, con confidence):\n",
        "{\n",
        "  \"tipologia_documento\": {\n",
        "    \"valore\": \"lettera privata\",\n",
        "    \"confidence\": 0.92,\n",
        "    \"fonte\": \"agente_analisi\"\n",
        "  },\n",
        "  \"lingua\": {\n",
        "    \"valore\": \"italiano\",\n",
        "    \"confidence\": 0.95,\n",
        "    \"fonte\": \"agente_analisi\"\n",
        "  },\n",
        "  \"composizione_oggetto\": {\n",
        "    \"valore\": \"documento costituito da una singola pagina manoscritta\",\n",
        "    \"confidence\": 0.88,\n",
        "    \"fonte\": \"agente_analisi\"\n",
        "  }\n",
        "}\n",
        "\n",
        "TRASCRIZIONE (fonte secondaria):\n",
        "<archivaldescription>05.1064</archivaldescription>\n",
        "\n",
        "<transcription>\n",
        "<date>Sabato 16. dicembre</date>\n",
        "\n",
        "<recipient>Caro Signor Torelli</recipient>,\n",
        "\n",
        "questa mia dovr√† giungerle tardi: ma sappia che solamente ieri ho\n",
        "ricevuto la sua pregiatissima degli 11. Invano mi stimola VS: io sono un\n",
        "povero vecchio, che da un pezzo non fa e non pu√≤ fare la minima\n",
        "cosa. Io m'aspetto (e desidero) ogni giorno il morire.\n",
        "Le rendo mille grazie del suo giornale, che vo ricevendo. Io le deside-\n",
        "ro di cuore ogni lunghezza e pienezza di prosperit√†: ella si assicuri\n",
        "del mio buon volere; ma compatisca l'impossibilit√†.\n",
        "\n",
        "<sender>Suo Affez.mo Servitore\n",
        "pietro giordani.</sender>\n",
        "</transcription>\n",
        "\n",
        "REGESTO CORRETTO:\n",
        "Pietro Giordani scrive al Signor Torelli il 16 dicembre 1843 per ringraziarlo della sua lettera dell'11. Si scusa per non poter fare di pi√π a causa della sua et√† avanzata e delle sue condizioni di salute precarie. Ringrazia Torelli per l'invio del giornale e gli augura ogni prosperit√†.\n",
        "\n",
        "ANALISI DELLE FONTI UTILIZZATE:\n",
        "{\n",
        "  \"mittente\": \"metadati_esterni\",\n",
        "  \"destinatario\": \"trascrizione_tag_xml\",\n",
        "  \"data\": \"metadati_esterni\",\n",
        "  \"luogo\": \"non_presente\",\n",
        "  \"contenuto\": \"trascrizione_testo\",\n",
        "  \"tipologia\": \"analisi_paleografica\"\n",
        "}\n",
        "\n",
        "MOTIVAZIONE:\n",
        "‚úì Mittente: METADATI ESTERNI (campo \"autore\") - fonte primaria\n",
        "‚úì Data: METADATI ESTERNI (campo \"data di creazione\") - fonte primaria, validata da tag XML\n",
        "‚úì Destinatario: TAG XML <recipient> - fonte secondaria affidabile\n",
        "‚úì Contenuto: TRASCRIZIONE testo - uso appropriato per tema\n",
        "‚úì Tipologia: ANALISI PALEOGRAFICA - confidence 0.92 (alta affidabilit√†)\n",
        "\n",
        "------------------------------------------------------------\n",
        "\n",
        "--- ESEMPIO 2 ---\n",
        "\n",
        "METADATI ESTERNI (fonte primaria):\n",
        "{\n",
        "  \"autore\": \"Sibilla Aleramo\",\n",
        "  \"data di creazione\": \"20 aprile 1957\"\n",
        "}\n",
        "\n",
        "ANALISI PALEOGRAFICA (fonte primaria):\n",
        "{\n",
        "  \"tipologia_documento\": {\n",
        "    \"valore\": \"lettera privata\",\n",
        "    \"confidence\": 0.88,\n",
        "    \"fonte\": \"agente_analisi\"\n",
        "  },\n",
        "  \"lingua\": {\n",
        "    \"valore\": \"italiano\",\n",
        "    \"confidence\": 0.93,\n",
        "    \"fonte\": \"agente_analisi\"\n",
        "  }\n",
        "}\n",
        "\n",
        "TRASCRIZIONE (fonte secondaria):\n",
        "<archivaldescription>05.1254 bis</archivaldescription>\n",
        "\n",
        "<transcription>\n",
        "<place_sender>Ancona</place_sender>, <date>20 Aprile 1957\n",
        "Vigilia di Pasqua</date>\n",
        "<recipient>A Elio Fiore,</recipient>\n",
        "carissimo,\n",
        "ho riletta qui la tua lettera,\n",
        "che ti somiglia e quindi avvalora\n",
        "l'affetto che sento per te e la fiducia\n",
        "che ho nel tuo avvenire di poeta. Anche\n",
        "la tristezza di cui mi parli comprendo,\n",
        "anch'io l'ho vissuta e talora ancora mi\n",
        "coglie, ma i poeti sempre la domi=\n",
        "nano e vincono, volta a volta. Avanti,\n",
        "Fiore! Sono contenta che i miei ottan=\n",
        "t'anni dian forza alle tue venti pri=\n",
        "mavere. Ti abbraccio. Sar√≤ di ritorno\n",
        "a Roma mercoled√¨ e ci telefoneremo. Sono\n",
        "stata un'ora al sole nel giardinetto di mio\n",
        "figlio e ho il capo un po' svagato! <sender>Sibilla</sender>\n",
        "</transcription>\n",
        "\n",
        "REGESTO CORRETTO:\n",
        "Sibilla Aleramo scrive ad Elio Fiore il 20 aprile 1957 da Ancona. Esprime comprensione per la tristezza del destinatario e lo esorta a dominare questo sentimento attraverso la poesia. Si dichiara lieta che i suoi ottant'anni possano dare forza alle venti primavere del giovane poeta.\n",
        "\n",
        "ANALISI DELLE FONTI UTILIZZATE:\n",
        "{\n",
        "  \"mittente\": \"metadati_esterni\",\n",
        "  \"destinatario\": \"trascrizione_tag_xml\",\n",
        "  \"data\": \"metadati_esterni\",\n",
        "  \"luogo\": \"trascrizione_tag_xml\",\n",
        "  \"contenuto\": \"trascrizione_testo\",\n",
        "  \"tipologia\": \"analisi_paleografica\"\n",
        "}\n",
        "\n",
        "MOTIVAZIONE:\n",
        "‚úì Mittente: METADATI ESTERNI (campo \"autore\") - fonte primaria\n",
        "‚úì Data: METADATI ESTERNI (fonte primaria) - validata da tag XML\n",
        "‚úì Luogo: TAG XML <place_sender> - fonte secondaria affidabile\n",
        "‚úì Destinatario: TAG XML <recipient> - fonte secondaria affidabile\n",
        "‚úì Contenuto: TRASCRIZIONE testo - uso appropriato\n",
        "‚úì Tipologia: ANALISI PALEOGRAFICA - confidence 0.88 (affidabile)\n",
        "\n",
        "------------------------------------------------------------\n",
        "\n",
        "--- ESEMPIO 3 (caso con incertezza) ---\n",
        "\n",
        "METADATI ESTERNI (fonte primaria):\n",
        "{\n",
        "  \"tipologia\": \"corrispondenza\"\n",
        "}\n",
        "\n",
        "ANALISI PALEOGRAFICA (fonte primaria):\n",
        "{\n",
        "  \"tipologia_documento\": {\n",
        "    \"valore\": \"lettera ufficiale\",\n",
        "    \"confidence\": 0.55,\n",
        "    \"fonte\": \"agente_analisi\"\n",
        "  },\n",
        "  \"lingua\": {\n",
        "    \"valore\": \"italiano\",\n",
        "    \"confidence\": 0.90,\n",
        "    \"fonte\": \"agente_analisi\"\n",
        "  }\n",
        "}\n",
        "\n",
        "TRASCRIZIONE (fonte secondaria):\n",
        "[testo senza tag XML chiari, scrittura difficile da decifrare]\n",
        "Il sottoscritto... richiede... documentazione...\n",
        "[parti illeggibili]\n",
        "\n",
        "REGESTO CORRETTO:\n",
        "Lettera (probabilmente di carattere ufficiale) in cui il mittente richiede documentazione. La scrittura presenta numerose parti illeggibili che non permettono di identificare con certezza mittente, destinatario e data.\n",
        "\n",
        "ANALISI DELLE FONTI UTILIZZATE:\n",
        "{\n",
        "  \"mittente\": \"non_determinabile\",\n",
        "  \"destinatario\": \"non_determinabile\",\n",
        "  \"data\": \"non_presente\",\n",
        "  \"contenuto\": \"trascrizione_testo_parziale\",\n",
        "  \"tipologia\": \"analisi_paleografica_bassa_confidence\"\n",
        "}\n",
        "\n",
        "NOTE: \"Confidence della tipologia documento molto bassa (0.55). Trascrizione incompleta. Impossibile determinare mittente e destinatario dalle fonti disponibili.\"\n",
        "\n",
        "MOTIVAZIONE:\n",
        "‚úì Tipologia con cautela: confidence 0.55 ‚Üí uso \"probabilmente\"\n",
        "‚úì Mittente/destinatario: non presenti in metadati esterni n√© in tag XML ‚Üí omessi\n",
        "‚úì Data: assente in tutte le fonti primarie ‚Üí omessa\n",
        "‚úì Contenuto: dalla trascrizione ma segnalando lacune\n",
        "‚úì Note: segnala esplicitamente le limitazioni\n",
        "\n",
        "------------------------------------------------------------\n",
        "\n",
        "============================================================\n",
        "DOCUMENTO DA ANALIZZARE:\n",
        "============================================================\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "        # METADATI ESTERNI (fonte primaria)\n",
        "        prompt += f\"\\nüìò METADATI ESTERNI (fonte primaria - massima priorit√†):\\n\"\n",
        "        prompt += json.dumps(context['metadati_esterni'], indent=2, ensure_ascii=False) + \"\\n\"\n",
        "\n",
        "        # ANALISI CON CONFIDENCE (fonte primaria)\n",
        "        prompt += f\"\\nüîç ANALISI PALEOGRAFICA E DOCUMENTARIA (fonte primaria - include confidence):\\n\"\n",
        "        analisi_strutturata = {}\n",
        "        for k, v in context['analisi'].items():\n",
        "            analisi_strutturata[k] = {\n",
        "                \"valore\": v['valore'],\n",
        "                \"confidence\": v['confidence'],\n",
        "                \"fonte\": v['modificato_da']\n",
        "            }\n",
        "        prompt += json.dumps(analisi_strutturata, indent=2, ensure_ascii=False) + \"\\n\"\n",
        "\n",
        "        # TRASCRIZIONE (fonte secondaria)\n",
        "        prompt += f\"\\nüìÑ TRASCRIZIONE (fonte secondaria - potenzialmente rumorosa):\\n\"\n",
        "        prompt += f\"{context['trascrizione']}\\n\"\n",
        "\n",
        "        prompt += \"\"\"\n",
        "============================================================\n",
        "ISTRUZIONI FINALI PER LA CREAZIONE DEL REGESTO:\n",
        "============================================================\n",
        "\n",
        "1. Rispetta RIGOROSAMENTE la gerarchia delle fonti sopra definita\n",
        "2. Per mittente, destinatario, data, luogo:\n",
        "   ‚Üí Priorit√† 1: METADATI ESTERNI\n",
        "   ‚Üí Priorit√† 2: TAG XML nella trascrizione (<sender>, <recipient>, <date>, <place_sender>)\n",
        "   ‚Üí Priorit√† 3: Testo libero (SOLO se necessario e con cautela)\n",
        "   ‚Üí Se impossibile determinare con certezza: OMETTI o usa formulazioni caute\n",
        "\n",
        "3. Per tipologia documento:\n",
        "   ‚Üí Usa ANALISI PALEOGRAFICA (campo \"tipologia_documento\")\n",
        "   ‚Üí Se confidence ‚â• 0.75: usa con fiducia\n",
        "   ‚Üí Se confidence < 0.6: usa formulazioni caute (\"probabilmente\", \"sembra\")\n",
        "\n",
        "4. Per il contenuto/tema:\n",
        "   ‚Üí Usa la TRASCRIZIONE (√® affidabile per questo scopo)\n",
        "   ‚Üí Sintetizza il messaggio principale in modo chiaro\n",
        "\n",
        "5. In caso di CONFLITTO tra fonti:\n",
        "   ‚Üí Prevalgono SEMPRE le fonti di livello superiore\n",
        "   ‚Üí METADATI ESTERNI > ANALISI PALEOGRAFICA > TAG XML > TESTO LIBERO\n",
        "\n",
        "6. Gestione incertezza:\n",
        "   ‚Üí Preferisci OMETTERE informazioni incerte piuttosto che inventarle\n",
        "   ‚Üí Se usi dati con confidence < 0.6, segnalalo con formulazioni caute\n",
        "   ‚Üí Se devi usare solo testo libero per info importanti, menzionalo nelle note\n",
        "\n",
        "FORMATO OUTPUT (JSON):\n",
        "{\n",
        "  \"regesto\": \"Il testo del regesto qui (max 100 parole, terza persona)...\",\n",
        "  \"note\": \"Eventuali osservazioni metodologiche: fonti mancanti, incertezze, confidence basse utilizzate, etc.\",\n",
        "  \"fonti_utilizzate\": {\n",
        "    \"mittente\": \"metadati_esterni | trascrizione_tag_xml | trascrizione_testo | non_presente | non_determinabile\",\n",
        "    \"destinatario\": \"metadati_esterni | trascrizione_tag_xml | trascrizione_testo | non_presente | non_determinabile\",\n",
        "    \"data\": \"metadati_esterni | trascrizione_tag_xml | trascrizione_testo | non_presente | non_determinabile\",\n",
        "    \"luogo\": \"metadati_esterni | trascrizione_tag_xml | trascrizione_testo | non_presente | non_determinabile\",\n",
        "    \"contenuto\": \"trascrizione_testo | trascrizione_parziale\",\n",
        "    \"tipologia\": \"analisi_paleografica | analisi_paleografica_bassa_confidence\"\n",
        "  }\n",
        "}\n",
        "\n",
        "‚ö†Ô∏è IMPORTANTE:\n",
        "- Compila il campo \"fonti_utilizzate\" con PRECISIONE per ogni informazione\n",
        "- Sii ONESTO nelle note se hai dovuto usare fonti di bassa qualit√†\n",
        "- Il regesto deve essere FATTUALE, non speculativo\n",
        "\n",
        "Rispondi SOLO con il JSON, senza altro testo.\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "def load_images_from_folder(folder_path: str, extensions: tuple = ('.jpg', '.jpeg', '.png')) -> List[str]:\n",
        "    \"\"\"Carica tutti i path delle immagini da una cartella, ordinati alfabeticamente\"\"\"\n",
        "    folder = Path(folder_path)\n",
        "\n",
        "    if not folder.exists():\n",
        "        raise ValueError(f\"La cartella non esiste: {folder_path}\")\n",
        "\n",
        "    if not folder.is_dir():\n",
        "        raise ValueError(f\"Il path non √® una cartella: {folder_path}\")\n",
        "\n",
        "    immagini_set = set()\n",
        "    for ext in extensions:\n",
        "        immagini_set.update(folder.glob(f\"*{ext}\"))\n",
        "        immagini_set.update(folder.glob(f\"*{ext.upper()}\"))\n",
        "\n",
        "    if not immagini_set:\n",
        "        raise ValueError(f\"Nessuna immagine trovata nella cartella: {folder_path}\")\n",
        "\n",
        "    immagini_sorted = sorted([str(img.absolute()) for img in immagini_set])\n",
        "\n",
        "    return immagini_sorted\n",
        "\n",
        "class Orchestrator:\n",
        "    \"\"\"Orchestratore che coordina gli agenti e gestisce il workflow\"\"\"\n",
        "\n",
        "    def __init__(self, llm_provider: str = \"anthropic\", api_key: Optional[str] = None,\n",
        "                 preprocess_images: bool = True, contrast_factor: float = 2.0,\n",
        "                 save_preview: bool = False, preview_folder: str = \"./preview\",\n",
        "                 use_prompt_caching: bool = True):\n",
        "        \"\"\"\n",
        "        Inizializza l'orchestratore con le configurazioni necessarie\n",
        "\n",
        "        Args:\n",
        "            llm_provider: Provider LLM da utilizzare (default: \"anthropic\")\n",
        "            api_key: Chiave API per il provider LLM\n",
        "            preprocess_images: Se True, converte immagini in B&W e aumenta contrasto\n",
        "            contrast_factor: Fattore di aumento contrasto (1.0-3.0, default 2.0)\n",
        "            save_preview: Se True, salva le immagini preprocessate per visualizzarle\n",
        "            preview_folder: Cartella dove salvare le preview (default \"./preview\")\n",
        "            use_prompt_caching: Se True, usa Prompt Caching di Anthropic per ridurre costi\n",
        "        \"\"\"\n",
        "        self.memory = SharedMemory()\n",
        "        self.llm_client = LLMClient(\n",
        "            provider=llm_provider,\n",
        "            api_key=api_key,\n",
        "            use_prompt_caching=use_prompt_caching\n",
        "        )\n",
        "\n",
        "        self.preprocess_images = preprocess_images\n",
        "        self.contrast_factor = contrast_factor\n",
        "        self.save_preview = save_preview\n",
        "        self.preview_folder = preview_folder\n",
        "        self.use_prompt_caching = use_prompt_caching\n",
        "        self.metadati_completi_file = None\n",
        "\n",
        "        # Crea gli agenti e passa le impostazioni di preprocessing\n",
        "        self.agent_analysis = AgentAnalysis(self.memory, self.llm_client)\n",
        "        self.agent_analysis._orchestrator_settings = {\n",
        "            'preprocess': preprocess_images,\n",
        "            'contrast': contrast_factor,\n",
        "            'save_preview': save_preview,\n",
        "            'preview_folder': preview_folder\n",
        "        }\n",
        "\n",
        "        self.agent_transcription = AgentTranscription(self.memory, self.llm_client)\n",
        "        self.agent_transcription._orchestrator_settings = {\n",
        "            'preprocess': preprocess_images,\n",
        "            'contrast': contrast_factor,\n",
        "            'save_preview': save_preview,\n",
        "            'preview_folder': preview_folder\n",
        "        }\n",
        "\n",
        "        self.agent_regesto = AgentRegesto(self.memory, self.llm_client)\n",
        "\n",
        "\n",
        "    def process_manuscript(self, metadati_file: str,\n",
        "                          cartella_immagini: str,\n",
        "                          metadati_completi_file: Optional[str] = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Processo completo: dall'input al risultato finale\n",
        "\n",
        "        Args:\n",
        "            metadati_file: Path al file JSON con i metadati descrittivi essenziali\n",
        "            cartella_immagini: Path alla cartella contenente le immagini del manoscritto\n",
        "            metadati_completi_file: Path al file JSON con metadati tecnici completi (opzionale)\n",
        "\n",
        "        Returns:\n",
        "            Dict contenente metadati, trascrizione e regesto\n",
        "        \"\"\"\n",
        "        print(\"=\"*60)\n",
        "        print(\"INIZIO ORCHESTRAZIONE\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # 1. Carica metadati esterni (essenziali)\n",
        "        with open(metadati_file, 'r', encoding='utf-8') as f:\n",
        "            metadati = json.load(f)\n",
        "\n",
        "        # Estrai i metadati dal primo (e unico) oggetto\n",
        "        for key, value in metadati.items():\n",
        "            if isinstance(value, dict) and \"metadati_descrittivi\" in value:\n",
        "                metadati_descrittivi = value[\"metadati_descrittivi\"]\n",
        "                break\n",
        "        else:\n",
        "            metadati_descrittivi = metadati\n",
        "\n",
        "        self.memory.set_metadati_esterni(metadati_descrittivi)\n",
        "\n",
        "        # 1b. Salva il path dei metadati completi per uso successivo\n",
        "        self.metadati_completi_file = metadati_completi_file\n",
        "\n",
        "        # 2. Carica immagini dalla cartella\n",
        "        immagini_paths = load_images_from_folder(cartella_immagini)\n",
        "        self.memory.set_immagini(immagini_paths)\n",
        "\n",
        "        print(f\"\\nüìÅ Caricate {len(immagini_paths)} immagini:\")\n",
        "        for i, path in enumerate(immagini_paths, 1):\n",
        "            print(f\"  {i}. {Path(path).name}\")\n",
        "\n",
        "        if self.preprocess_images:\n",
        "            print(f\"\\nüñºÔ∏è  PREPROCESSING ATTIVO:\")\n",
        "            print(f\"  - Conversione in bianco e nero\")\n",
        "            print(f\"  - Aumento contrasto: {self.contrast_factor}x\")\n",
        "            if self.save_preview:\n",
        "                print(f\"  - Preview salvate in: {self.preview_folder}/\")\n",
        "\n",
        "        # 3. Analisi iniziale (CREA la cache)\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"FASE 1: ANALISI (crea cache)\")\n",
        "        print(\"=\"*60)\n",
        "        self.agent_analysis.analyze()\n",
        "\n",
        "        # 4. Trascrizione CON VALIDAZIONE contro metadati esterni (USA la cache!)\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"FASE 2: TRASCRIZIONE (usa cache + validazione metadati esterni)\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        risultato_trascrizione = self.agent_transcription.transcribe()\n",
        "\n",
        "        # Stampa eventuali correzioni applicate\n",
        "        if risultato_trascrizione.get(\"correzioni_applicate\"):\n",
        "            print(\"\\n‚ö†Ô∏è CORREZIONI APPLICATE basate su metadati esterni:\")\n",
        "            for correzione in risultato_trascrizione[\"correzioni_applicate\"]:\n",
        "                print(f\"  ‚Ä¢ {correzione}\")\n",
        "\n",
        "        # Stampa eventuali contraddizioni rilevate\n",
        "        if risultato_trascrizione.get(\"contraddizioni_rilevate\"):\n",
        "            print(\"\\n‚ö†Ô∏è CONTRADDIZIONI RILEVATE e risolte:\")\n",
        "            for contraddizione in risultato_trascrizione[\"contraddizioni_rilevate\"]:\n",
        "                print(f\"  ‚Ä¢ Campo '{contraddizione['campo']}':\")\n",
        "                print(f\"    - Visto nel documento: {contraddizione['valore_visto_documento']}\")\n",
        "                print(f\"    - Metadati esterni: {contraddizione['valore_metadati_esterni']}\")\n",
        "                print(f\"    - Azione: {contraddizione['azione']}\")\n",
        "\n",
        "        print(\"\\n‚úì Trascrizione completata!\")\n",
        "\n",
        "        # 5. Crea il regesto con gerarchia epistemica (SOLO TEXT - no vision)\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"FASE 3: REGESTO (GERARCHIA EPISTEMICA - solo text)\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        regesto_risultato = None\n",
        "        if self.memory.trascrizione:\n",
        "            try:\n",
        "                regesto_risultato = self.agent_regesto.crea_regesto()\n",
        "\n",
        "                # Stampa le fonti utilizzate per debug\n",
        "                if regesto_risultato and \"fonti_utilizzate\" in regesto_risultato:\n",
        "                    print(f\"\\nüìä Fonti utilizzate per il regesto:\")\n",
        "                    for campo, fonte in regesto_risultato[\"fonti_utilizzate\"].items():\n",
        "                        print(f\"  ‚Ä¢ {campo}: {fonte}\")\n",
        "\n",
        "                # Stampa eventuali note metodologiche\n",
        "                if regesto_risultato and regesto_risultato.get(\"note\"):\n",
        "                    print(f\"\\nüìù Note metodologiche: {regesto_risultato['note']}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\n‚ö†Ô∏è Errore nella creazione del regesto: {e}\")\n",
        "\n",
        "\n",
        "        # 6. Prepara output finale\n",
        "        output = self._prepara_output(risultato_trascrizione, regesto_risultato)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"FINE ORCHESTRAZIONE\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def _carica_metadati_tecnici(self) -> Optional[Dict]:\n",
        "        \"\"\"Carica i metadati tecnici dal file metadati_completi.json\"\"\"\n",
        "        if not self.metadati_completi_file:\n",
        "            print(\"[INFO] Nessun file metadati_completi specificato\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            print(f\"[INFO] Caricamento metadati tecnici da: {self.metadati_completi_file}\")\n",
        "\n",
        "            with open(self.metadati_completi_file, 'r', encoding='utf-8') as f:\n",
        "                dati_completi = json.load(f)\n",
        "\n",
        "            # Estrai la sezione immagini\n",
        "            # Il formato √®: {CNMD...: {\"metadati_descrittivi\": ..., \"immagini\": [...], \"statistiche\": ...}}\n",
        "            for chiave, contenuto in dati_completi.items():\n",
        "                if \"immagini\" in contenuto:\n",
        "                    return {\n",
        "                        \"immagini\": contenuto[\"immagini\"],\n",
        "                        \"statistiche\": contenuto.get(\"statistiche\", {})\n",
        "                    }\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[WARNING] Errore nel caricamento metadati tecnici: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _prepara_output(self, risultato_trascrizione: Dict, regesto_risultato: Optional[Dict] = None) -> Dict:\n",
        "        \"\"\"Prepara l'output finale con metadati (descrittivi + tecnici), trascrizione e regesto\"\"\"\n",
        "        context = self.memory.get_all_context()\n",
        "\n",
        "        # Estrai solo i valori dai metadati analizzati, senza confidence e versioni precedenti\n",
        "        metadati_analizzati = {}\n",
        "        for chiave, dati in context[\"analisi\"].items():\n",
        "            metadati_analizzati[chiave] = dati[\"valore\"]\n",
        "\n",
        "        # Carica i metadati tecnici se disponibili\n",
        "        metadati_tecnici = self._carica_metadati_tecnici()\n",
        "\n",
        "        # Output completo\n",
        "        output = {\n",
        "            \"metadati_descrittivi_inseriti_manualmente\": context[\"metadati_esterni\"],\n",
        "            \"metadati_descrittivi_LLM\": metadati_analizzati,\n",
        "            \"trascrizione\": self.memory.trascrizione or \"\"\n",
        "        }\n",
        "\n",
        "        # Aggiungi informazioni sulla trascrizione (correzioni, contraddizioni)\n",
        "        if risultato_trascrizione.get(\"correzioni_applicate\"):\n",
        "            output[\"trascrizione_correzioni_applicate\"] = risultato_trascrizione[\"correzioni_applicate\"]\n",
        "\n",
        "        if risultato_trascrizione.get(\"contraddizioni_rilevate\"):\n",
        "            output[\"trascrizione_contraddizioni_rilevate\"] = risultato_trascrizione[\"contraddizioni_rilevate\"]\n",
        "\n",
        "        if risultato_trascrizione.get(\"aree_incerte\"):\n",
        "            output[\"trascrizione_aree_incerte\"] = risultato_trascrizione[\"aree_incerte\"]\n",
        "\n",
        "        # Aggiungi il regesto se disponibile\n",
        "        if regesto_risultato and regesto_risultato.get(\"regesto\"):\n",
        "            output[\"regesto\"] = regesto_risultato[\"regesto\"]\n",
        "\n",
        "            # Aggiungi anche le fonti utilizzate per il regesto (utile per debugging e validazione)\n",
        "            if \"fonti_utilizzate\" in regesto_risultato:\n",
        "                output[\"regesto_fonti_utilizzate\"] = regesto_risultato[\"fonti_utilizzate\"]\n",
        "\n",
        "            # Aggiungi il metodo usato\n",
        "            if \"metodo\" in regesto_risultato:\n",
        "                output[\"regesto_metodo\"] = regesto_risultato[\"metodo\"]\n",
        "\n",
        "            # Aggiungi note metodologiche se presenti\n",
        "            if \"note\" in regesto_risultato and regesto_risultato[\"note\"]:\n",
        "                output[\"regesto_note_metodologiche\"] = regesto_risultato[\"note\"]\n",
        "\n",
        "        # Aggiungi metadati tecnici se disponibili\n",
        "        if metadati_tecnici:\n",
        "            output[\"metadati_tecnici\"] = metadati_tecnici\n",
        "\n",
        "        return output\n",
        "\n",
        "    def print_report(self, output: Dict):\n",
        "        \"\"\"Stampa un report leggibile del risultato\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"REPORT FINALE\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(\"\\nüìä METADATI DESCRITTIVI ANALIZZATI:\")\n",
        "        for chiave, valore in output['metadati_descrittivi_LLM'].items():\n",
        "            val_str = str(valore)\n",
        "            if len(val_str) > 100:\n",
        "                val_str = val_str[:100] + \"...\"\n",
        "            print(f\"  {chiave}: {val_str}\")\n",
        "\n",
        "        if \"metadati_tecnici\" in output:\n",
        "            print(\"\\nüîß METADATI TECNICI:\")\n",
        "            stats = output['metadati_tecnici'].get('statistiche', {})\n",
        "            print(f\"  Numero immagini: {stats.get('numero_immagini', 0)}\")\n",
        "            if output['metadati_tecnici'].get('immagini'):\n",
        "                print(f\"  Dettagli immagini disponibili: {len(output['metadati_tecnici']['immagini'])}\")\n",
        "\n",
        "        print(\"\\nüìÑ TRASCRIZIONE:\")\n",
        "        if output.get('trascrizione'):\n",
        "            trascrizione = output['trascrizione']\n",
        "            if len(trascrizione) > 400:\n",
        "                print(f\"  {trascrizione[:400]}...\")\n",
        "                print(f\"  [...trascrizione completa: {len(trascrizione)} caratteri totali]\")\n",
        "            else:\n",
        "                print(f\"  {trascrizione}\")\n",
        "        else:\n",
        "            print(\"  Nessuna trascrizione disponibile\")\n",
        "\n",
        "        # Mostra correzioni applicate nella trascrizione\n",
        "        if \"trascrizione_correzioni_applicate\" in output and output[\"trascrizione_correzioni_applicate\"]:\n",
        "            print(\"\\n‚ö†Ô∏è CORREZIONI APPLICATE NELLA TRASCRIZIONE:\")\n",
        "            for correzione in output[\"trascrizione_correzioni_applicate\"]:\n",
        "                print(f\"  ‚Ä¢ {correzione}\")\n",
        "\n",
        "        # Mostra contraddizioni rilevate nella trascrizione\n",
        "        if \"trascrizione_contraddizioni_rilevate\" in output and output[\"trascrizione_contraddizioni_rilevate\"]:\n",
        "            print(\"\\n‚ö†Ô∏è CONTRADDIZIONI RILEVATE E RISOLTE:\")\n",
        "            for contraddizione in output[\"trascrizione_contraddizioni_rilevate\"]:\n",
        "                print(f\"  ‚Ä¢ Campo '{contraddizione['campo']}':\")\n",
        "                print(f\"    Visto: {contraddizione['valore_visto_documento']}\")\n",
        "                print(f\"    Corretto con: {contraddizione['valore_metadati_esterni']}\")\n",
        "\n",
        "        # Regesto\n",
        "        if \"regesto\" in output:\n",
        "            print(\"\\nüìã REGESTO:\")\n",
        "            print(f\"  {output['regesto']}\")\n",
        "\n",
        "            # Mostra il metodo usato\n",
        "            if \"regesto_metodo\" in output:\n",
        "                print(f\"\\n  Metodo: {output['regesto_metodo']}\")\n",
        "\n",
        "            # Mostra le fonti utilizzate (importante per validazione)\n",
        "            if \"regesto_fonti_utilizzate\" in output:\n",
        "                print(f\"\\n  üìä Fonti utilizzate:\")\n",
        "                for campo, fonte in output['regesto_fonti_utilizzate'].items():\n",
        "                    print(f\"    ‚Ä¢ {campo}: {fonte}\")\n",
        "\n",
        "            # Mostra note metodologiche se presenti\n",
        "            if \"regesto_note_metodologiche\" in output:\n",
        "                print(f\"\\n  üìù Note metodologiche: {output['regesto_note_metodologiche']}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# ESEMPIO D'USO\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Configurazione\n",
        "    orchestrator = Orchestrator(\n",
        "        llm_provider=\"anthropic\",\n",
        "        api_key=\"\",\n",
        "        preprocess_images=True,\n",
        "        contrast_factor=2.0,\n",
        "        save_preview=True,\n",
        "        preview_folder=\"./preview\",\n",
        "        use_prompt_caching=True\n",
        "    )\n",
        "\n",
        "    # Path ai file\n",
        "    metadati_essenziali = \"05.1066\\\\05_metadati_essenziali.json\"\n",
        "    metadati_completi = \"05.1066\\\\05_metadati_completi.json\"\n",
        "    cartella_immagini = \"05.1066\"\n",
        "\n",
        "    try:\n",
        "        # Esegui il processo completo\n",
        "        output = orchestrator.process_manuscript(\n",
        "            metadati_file=metadati_essenziali,\n",
        "            cartella_immagini=cartella_immagini,\n",
        "            metadati_completi_file=metadati_completi\n",
        "        )\n",
        "        orchestrator.print_report(output)\n",
        "\n",
        "        # Salva output come JSON\n",
        "        with open(\"output_trascrizione.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(output, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(\"\\n‚úì Output salvato in 'output_trascrizione.json'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Errore durante l'esecuzione: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43cd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing noise...\n",
      "Transcribing...\n",
      "Running diarization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlab/miniconda3/envs/digimab/lib/python3.10/site-packages/pyannote/audio/models/blocks/pooling.py:103: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1857.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nessun metodo funziona: 'DiarizeOutput' object is not iterable\n",
      "Tipo oggetto: <class 'pyannote.audio.pipelines.speaker_diarization.DiarizeOutput'>\n",
      "Attributi: ['exclusive_speaker_diarization', 'serialize', 'speaker_diarization', 'speaker_embeddings']\n",
      "Segmenti diarization trovati: 0\n",
      "Segmenti dopo merge: 1\n",
      "Saving diarized transcription...\n",
      "Trascrizione diarizzata salvata: trascrizione_diarizzata.txt / .json\n",
      "Processing chunk 1/2\n",
      "Processing chunk 2/2\n",
      "\n",
      "âœ… Pipeline completa.\n",
      "   ðŸ“„ trascrizione_diarizzata.txt  â€” trascrizione con speaker e timestamp\n",
      "   ðŸ“‹ trascrizione_diarizzata.json â€” trascrizione strutturata in JSON\n",
      "   ðŸ“ regesto_finale.txt           â€” regesto accademico\n",
      "   ðŸ“¦ regesto_finale.json          â€” regesto in JSON\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import json\n",
    "import math\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "from pyannote.audio import Pipeline\n",
    "from collections import defaultdict\n",
    "import anthropic\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "\n",
    "AUDIO_PATH = \"input/Corvatta_Intervista.mp3\"\n",
    "CLEAN_AUDIO_PATH = \"convegno_clean.wav\"\n",
    "HF_TOKEN = \"\"\n",
    "ANTHROPIC_API_KEY = \"\"\n",
    "CLAUDE_MODEL = \"claude-sonnet-4-6\"\n",
    "\n",
    "CHUNK_WORD_LIMIT = 4000\n",
    "\n",
    "# =========================\n",
    "# 1. NOISE REDUCTION\n",
    "# =========================\n",
    "\n",
    "print(\"Reducing noise...\")\n",
    "audio, sr = librosa.load(AUDIO_PATH, sr=None)\n",
    "noise_sample = audio[0:5*sr]\n",
    "\n",
    "reduced_noise = nr.reduce_noise(\n",
    "    y=audio,\n",
    "    sr=sr,\n",
    "    y_noise=noise_sample,\n",
    "    prop_decrease=0.8\n",
    ")\n",
    "\n",
    "sf.write(CLEAN_AUDIO_PATH, reduced_noise, sr)\n",
    "\n",
    "# =========================\n",
    "# 2. LOAD MODELS\n",
    "# =========================\n",
    "\n",
    "whisper_model = whisper.load_model(\"medium\")\n",
    "\n",
    "diarization_pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n",
    "claude_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "# =========================\n",
    "# 3. TRANSCRIPTION\n",
    "# =========================\n",
    "\n",
    "print(\"Transcribing...\")\n",
    "transcription = whisper_model.transcribe(\n",
    "    CLEAN_AUDIO_PATH,\n",
    "    language=\"it\",\n",
    "    word_timestamps=True\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 4. DIARIZATION\n",
    "# =========================\n",
    "\n",
    "print(\"Running diarization...\")\n",
    "diarization = diarization_pipeline(CLEAN_AUDIO_PATH)\n",
    "\n",
    "# =========================\n",
    "# 5. MERGE TRANSCRIPT + SPEAKERS\n",
    "# =========================\n",
    "\n",
    "segments_output = []\n",
    "\n",
    "diar_list = []\n",
    "\n",
    "try:\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        diar_list.append((turn.start, turn.end, speaker))\n",
    "    print(\"Metodo: itertracks\")\n",
    "except AttributeError:\n",
    "    try:\n",
    "        for row in diarization.segments:\n",
    "            diar_list.append((row.start, row.end, row.speaker))\n",
    "        print(\"Metodo: segments\")\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            for row in diarization:\n",
    "                diar_list.append((row.start, row.end, row.speaker))\n",
    "            print(\"Metodo: iterabile diretto\")\n",
    "        except Exception as e:\n",
    "            print(f\"Nessun metodo funziona: {e}\")\n",
    "            print(f\"Tipo oggetto: {type(diarization)}\")\n",
    "            print(f\"Attributi: {[x for x in dir(diarization) if not x.startswith('_')]}\")\n",
    "\n",
    "print(f\"Segmenti diarization trovati: {len(diar_list)}\")\n",
    "if diar_list:\n",
    "    print(f\"Esempio: {diar_list[0]}\")\n",
    "\n",
    "for segment in transcription[\"segments\"]:\n",
    "    seg_start = segment[\"start\"]\n",
    "    seg_end = segment[\"end\"]\n",
    "    seg_text = segment[\"text\"].strip()\n",
    "\n",
    "    speaker_label = \"UNKNOWN\"\n",
    "    best_overlap = 0\n",
    "\n",
    "    for (d_start, d_end, speaker) in diar_list:\n",
    "        overlap = min(d_end, seg_end) - max(d_start, seg_start)\n",
    "        if overlap > best_overlap:\n",
    "            best_overlap = overlap\n",
    "            speaker_label = speaker\n",
    "\n",
    "    segments_output.append({\n",
    "        \"speaker\": speaker_label,\n",
    "        \"start\": seg_start,\n",
    "        \"end\": seg_end,\n",
    "        \"text\": seg_text\n",
    "    })\n",
    "\n",
    "# Merge segmenti consecutivi dello stesso speaker\n",
    "merged_segments = []\n",
    "current = segments_output[0]\n",
    "\n",
    "for seg in segments_output[1:]:\n",
    "    if seg[\"speaker\"] == current[\"speaker\"]:\n",
    "        current[\"end\"] = seg[\"end\"]\n",
    "        current[\"text\"] += \" \" + seg[\"text\"]\n",
    "    else:\n",
    "        merged_segments.append(current)\n",
    "        current = seg\n",
    "\n",
    "merged_segments.append(current)\n",
    "\n",
    "print(f\"Segmenti dopo merge: {len(merged_segments)}\")\n",
    "\n",
    "# =========================\n",
    "# 6. IDENTIFY ROLES\n",
    "# =========================\n",
    "\n",
    "speaker_stats = defaultdict(lambda: {\n",
    "    \"total_duration\": 0,\n",
    "    \"num_segments\": 0,\n",
    "    \"total_words\": 0\n",
    "})\n",
    "\n",
    "for seg in merged_segments:\n",
    "    duration = seg[\"end\"] - seg[\"start\"]\n",
    "    words = len(seg[\"text\"].split())\n",
    "\n",
    "    speaker_stats[seg[\"speaker\"]][\"total_duration\"] += duration\n",
    "    speaker_stats[seg[\"speaker\"]][\"num_segments\"] += 1\n",
    "    speaker_stats[seg[\"speaker\"]][\"total_words\"] += words\n",
    "\n",
    "sorted_speakers = sorted(\n",
    "    speaker_stats.items(),\n",
    "    key=lambda x: x[1][\"total_duration\"],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "role_mapping = {}\n",
    "\n",
    "if sorted_speakers:\n",
    "    role_mapping[sorted_speakers[0][0]] = \"RELATORE_PRINCIPALE\"\n",
    "\n",
    "for speaker, stats in sorted_speakers[1:]:\n",
    "    avg_words = stats[\"total_words\"] / max(stats[\"num_segments\"], 1)\n",
    "\n",
    "    if stats[\"total_duration\"] > 0.15 * sorted_speakers[0][1][\"total_duration\"]:\n",
    "        role_mapping[speaker] = \"RELATORE_SECONDARIO\"\n",
    "    elif avg_words < 40:\n",
    "        role_mapping[speaker] = \"PUBBLICO\"\n",
    "    else:\n",
    "        role_mapping[speaker] = \"INTERVENTO\"\n",
    "\n",
    "for seg in merged_segments:\n",
    "    seg[\"role\"] = role_mapping.get(seg[\"speaker\"], \"UNKNOWN\")\n",
    "\n",
    "# =========================\n",
    "# 7. SAVE DIARIZED TRANSCRIPTION\n",
    "# =========================\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "    \"\"\"Converte secondi in formato HH:MM:SS\"\"\"\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "# Salva trascrizione diarizzata come TXT leggibile\n",
    "print(\"Saving diarized transcription...\")\n",
    "with open(\"trascrizione_diarizzata.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"TRASCRIZIONE DIARIZZATA\\n\")\n",
    "    f.write(f\"File: {AUDIO_PATH}\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    for seg in merged_segments:\n",
    "        ts_start = format_timestamp(seg[\"start\"])\n",
    "        ts_end = format_timestamp(seg[\"end\"])\n",
    "        f.write(f\"[{ts_start} â†’ {ts_end}]  {seg['role']} ({seg['speaker']})\\n\")\n",
    "        f.write(f\"{seg['text']}\\n\\n\")\n",
    "\n",
    "# Salva trascrizione diarizzata come JSON strutturato\n",
    "with open(\"trascrizione_diarizzata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"file_name\": AUDIO_PATH,\n",
    "        \"num_speakers\": len(speaker_stats),\n",
    "        \"speaker_stats\": {\n",
    "            spk: {\n",
    "                \"role\": role_mapping.get(spk, \"UNKNOWN\"),\n",
    "                \"total_duration_sec\": round(stats[\"total_duration\"], 2),\n",
    "                \"num_segments\": stats[\"num_segments\"],\n",
    "                \"total_words\": stats[\"total_words\"]\n",
    "            }\n",
    "            for spk, stats in speaker_stats.items()\n",
    "        },\n",
    "        \"segments\": [\n",
    "            {\n",
    "                \"speaker\": seg[\"speaker\"],\n",
    "                \"role\": seg[\"role\"],\n",
    "                \"start\": round(seg[\"start\"], 2),\n",
    "                \"end\": round(seg[\"end\"], 2),\n",
    "                \"duration\": round(seg[\"end\"] - seg[\"start\"], 2),\n",
    "                \"text\": seg[\"text\"]\n",
    "            }\n",
    "            for seg in merged_segments\n",
    "        ]\n",
    "    }, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Trascrizione diarizzata salvata: trascrizione_diarizzata.txt / .json\")\n",
    "\n",
    "# =========================\n",
    "# 8. BUILD FULL TEXT FOR REGESTO\n",
    "# =========================\n",
    "\n",
    "full_text = \"\"\n",
    "for seg in merged_segments:\n",
    "    full_text += f\"{seg['role']}: {seg['text']}\\n\\n\"\n",
    "\n",
    "# =========================\n",
    "# 9. CHUNKING\n",
    "# =========================\n",
    "\n",
    "def split_chunks(text, limit):\n",
    "    words = text.split()\n",
    "    return [\n",
    "        \" \".join(words[i:i+limit])\n",
    "        for i in range(0, len(words), limit)\n",
    "    ]\n",
    "\n",
    "chunks = split_chunks(full_text, CHUNK_WORD_LIMIT)\n",
    "\n",
    "# =========================\n",
    "# 10. PARTIAL REGESTI WITH CLAUDE\n",
    "# =========================\n",
    "\n",
    "partial_regesti = []\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {idx+1}/{len(chunks)}\")\n",
    "\n",
    "    response = claude_client.messages.create(\n",
    "        model=CLAUDE_MODEL,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.2,\n",
    "        system=\"Sei un redattore accademico esperto nella redazione di regesti.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "Redigi un regesto analitico della seguente parte di convegno.\n",
    "Non distinguere per speaker.\n",
    "Linguaggio formale scientifico.\n",
    "\n",
    "{chunk}\n",
    "\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    partial_text = response.content[0].text\n",
    "    partial_regesti.append(partial_text)\n",
    "\n",
    "# =========================\n",
    "# 11. FINAL REGESTO\n",
    "# =========================\n",
    "\n",
    "combined = \"\\n\\n\".join(partial_regesti)\n",
    "\n",
    "final_response = claude_client.messages.create(\n",
    "    model=CLAUDE_MODEL,\n",
    "    max_tokens=4000,\n",
    "    temperature=0.2,\n",
    "    system=\"Sei un esperto redattore scientifico.\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "Integra i seguenti regesti parziali in un unico regesto coerente dell'intero convegno.\n",
    "Evita ripetizioni. Nessun elenco puntato.\n",
    "Il regesto deve coprire tutte le parti dell'audio trascritto.\n",
    "IMPORTANTE: il regesto deve essere di al massimo 350 parole. \n",
    "\n",
    "{combined}\n",
    "\"\"\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_regesto = final_response.content[0].text\n",
    "\n",
    "# =========================\n",
    "# 12. SAVE REGESTO OUTPUT\n",
    "# =========================\n",
    "\n",
    "with open(\"regesto_finale.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_regesto)\n",
    "\n",
    "with open(\"regesto_finale.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"file_name\": AUDIO_PATH,\n",
    "        \"regesto_finale\": final_regesto\n",
    "    }, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# =========================\n",
    "# 13. SUMMARY\n",
    "# =========================\n",
    "\n",
    "print(\"\\nâœ… Pipeline completa.\")\n",
    "print(f\"   ðŸ“„ trascrizione_diarizzata.txt  â€” trascrizione con speaker e timestamp\")\n",
    "print(f\"   ðŸ“‹ trascrizione_diarizzata.json â€” trascrizione strutturata in JSON\")\n",
    "print(f\"   ðŸ“ regesto_finale.txt           â€” regesto accademico\")\n",
    "print(f\"   ðŸ“¦ regesto_finale.json          â€” regesto in JSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digimab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
